Search.setIndex({"docnames": ["UIO", "context", "index", "install", "jit_in_wenet", "lm", "papers", "pretrained_models", "pretrained_models.en", "production", "python_api/modules", "python_api/wenet", "python_api/wenet.branchformer", "python_api/wenet.branchformer.attention", "python_api/wenet.branchformer.cgmlp", "python_api/wenet.branchformer.embedding", "python_api/wenet.branchformer.encoder", "python_api/wenet.branchformer.encoder_layer", "python_api/wenet.branchformer.test_branchformer", "python_api/wenet.dataset", "python_api/wenet.dataset.dataset", "python_api/wenet.dataset.kaldi_io", "python_api/wenet.dataset.processor", "python_api/wenet.dataset.wav_distortion", "python_api/wenet.efficient_conformer", "python_api/wenet.efficient_conformer.attention", "python_api/wenet.efficient_conformer.convolution", "python_api/wenet.efficient_conformer.encoder", "python_api/wenet.efficient_conformer.encoder_layer", "python_api/wenet.efficient_conformer.subsampling", "python_api/wenet.squeezeformer", "python_api/wenet.squeezeformer.attention", "python_api/wenet.squeezeformer.conv2d", "python_api/wenet.squeezeformer.convolution", "python_api/wenet.squeezeformer.encoder", "python_api/wenet.squeezeformer.encoder_layer", "python_api/wenet.squeezeformer.positionwise_feed_forward", "python_api/wenet.squeezeformer.subsampling", "python_api/wenet.transducer", "python_api/wenet.transducer.joint", "python_api/wenet.transducer.predictor", "python_api/wenet.transducer.transducer", "python_api/wenet.transformer", "python_api/wenet.transformer.asr_model", "python_api/wenet.transformer.attention", "python_api/wenet.transformer.cmvn", "python_api/wenet.transformer.convolution", "python_api/wenet.transformer.ctc", "python_api/wenet.transformer.decoder", "python_api/wenet.transformer.decoder_layer", "python_api/wenet.transformer.embedding", "python_api/wenet.transformer.encoder", "python_api/wenet.transformer.encoder_layer", "python_api/wenet.transformer.label_smoothing_loss", "python_api/wenet.transformer.positionwise_feed_forward", "python_api/wenet.transformer.subsampling", "python_api/wenet.transformer.swish", "python_api/wenet.utils", "python_api/wenet.utils.checkpoint", "python_api/wenet.utils.cmvn", "python_api/wenet.utils.common", "python_api/wenet.utils.config", "python_api/wenet.utils.ctc_util", "python_api/wenet.utils.executor", "python_api/wenet.utils.file_utils", "python_api/wenet.utils.init_model", "python_api/wenet.utils.mask", "python_api/wenet.utils.scheduler", "python_binding", "reference", "requirements", "runtime", "train", "tutorial_aishell", "tutorial_librispeech"], "filenames": ["UIO.md", "context.md", "index.rst", "install.md", "jit_in_wenet.md", "lm.md", "papers.md", "pretrained_models.md", "pretrained_models.en.md", "production.rst", "python_api/modules.rst", "python_api/wenet.rst", "python_api/wenet.branchformer.rst", "python_api/wenet.branchformer.attention.rst", "python_api/wenet.branchformer.cgmlp.rst", "python_api/wenet.branchformer.embedding.rst", "python_api/wenet.branchformer.encoder.rst", "python_api/wenet.branchformer.encoder_layer.rst", "python_api/wenet.branchformer.test_branchformer.rst", "python_api/wenet.dataset.rst", "python_api/wenet.dataset.dataset.rst", "python_api/wenet.dataset.kaldi_io.rst", "python_api/wenet.dataset.processor.rst", "python_api/wenet.dataset.wav_distortion.rst", "python_api/wenet.efficient_conformer.rst", "python_api/wenet.efficient_conformer.attention.rst", "python_api/wenet.efficient_conformer.convolution.rst", "python_api/wenet.efficient_conformer.encoder.rst", "python_api/wenet.efficient_conformer.encoder_layer.rst", "python_api/wenet.efficient_conformer.subsampling.rst", "python_api/wenet.squeezeformer.rst", "python_api/wenet.squeezeformer.attention.rst", "python_api/wenet.squeezeformer.conv2d.rst", "python_api/wenet.squeezeformer.convolution.rst", "python_api/wenet.squeezeformer.encoder.rst", "python_api/wenet.squeezeformer.encoder_layer.rst", "python_api/wenet.squeezeformer.positionwise_feed_forward.rst", "python_api/wenet.squeezeformer.subsampling.rst", "python_api/wenet.transducer.rst", "python_api/wenet.transducer.joint.rst", "python_api/wenet.transducer.predictor.rst", "python_api/wenet.transducer.transducer.rst", "python_api/wenet.transformer.rst", "python_api/wenet.transformer.asr_model.rst", "python_api/wenet.transformer.attention.rst", "python_api/wenet.transformer.cmvn.rst", "python_api/wenet.transformer.convolution.rst", "python_api/wenet.transformer.ctc.rst", "python_api/wenet.transformer.decoder.rst", "python_api/wenet.transformer.decoder_layer.rst", "python_api/wenet.transformer.embedding.rst", "python_api/wenet.transformer.encoder.rst", "python_api/wenet.transformer.encoder_layer.rst", "python_api/wenet.transformer.label_smoothing_loss.rst", "python_api/wenet.transformer.positionwise_feed_forward.rst", "python_api/wenet.transformer.subsampling.rst", "python_api/wenet.transformer.swish.rst", "python_api/wenet.utils.rst", "python_api/wenet.utils.checkpoint.rst", "python_api/wenet.utils.cmvn.rst", "python_api/wenet.utils.common.rst", "python_api/wenet.utils.config.rst", "python_api/wenet.utils.ctc_util.rst", "python_api/wenet.utils.executor.rst", "python_api/wenet.utils.file_utils.rst", "python_api/wenet.utils.init_model.rst", "python_api/wenet.utils.mask.rst", "python_api/wenet.utils.scheduler.rst", "python_binding.md", "reference.rst", "requirements.txt", "runtime.md", "train.rst", "tutorial_aishell.md", "tutorial_librispeech.md"], "titles": ["Big Data Training: UIO", "Context Biasing", "Welcome to wenet\u2019s documentation!", "Install", "JIT in WeNet", "LM for WeNet", "Papers", "Pretrained Models in WeNet", "Pretrained Models in WeNet", "Production Runtime", "Python API Reference", "wenet package", "wenet.branchformer package", "wenet.branchformer.attention module", "wenet.branchformer.cgmlp module", "wenet.branchformer.embedding module", "wenet.branchformer.encoder module", "wenet.branchformer.encoder_layer module", "wenet.branchformer.test_branchformer module", "wenet.dataset package", "wenet.dataset.dataset module", "wenet.dataset.kaldi_io module", "wenet.dataset.processor module", "wenet.dataset.wav_distortion module", "wenet.efficient_conformer package", "wenet.efficient_conformer.attention module", "wenet.efficient_conformer.convolution module", "wenet.efficient_conformer.encoder module", "wenet.efficient_conformer.encoder_layer module", "wenet.efficient_conformer.subsampling module", "wenet.squeezeformer package", "wenet.squeezeformer.attention module", "wenet.squeezeformer.conv2d module", "wenet.squeezeformer.convolution module", "wenet.squeezeformer.encoder module", "wenet.squeezeformer.encoder_layer module", "wenet.squeezeformer.positionwise_feed_forward module", "wenet.squeezeformer.subsampling module", "wenet.transducer package", "wenet.transducer.joint module", "wenet.transducer.predictor module", "wenet.transducer.transducer module", "wenet.transformer package", "wenet.transformer.asr_model module", "wenet.transformer.attention module", "wenet.transformer.cmvn module", "wenet.transformer.convolution module", "wenet.transformer.ctc module", "wenet.transformer.decoder module", "wenet.transformer.decoder_layer module", "wenet.transformer.embedding module", "wenet.transformer.encoder module", "wenet.transformer.encoder_layer module", "wenet.transformer.label_smoothing_loss module", "wenet.transformer.positionwise_feed_forward module", "wenet.transformer.subsampling module", "wenet.transformer.swish module", "wenet.utils package", "wenet.utils.checkpoint module", "wenet.utils.cmvn module", "wenet.utils.common module", "wenet.utils.config module", "wenet.utils.ctc_util module", "wenet.utils.executor module", "wenet.utils.file_utils module", "wenet.utils.init_model module", "wenet.utils.mask module", "wenet.utils.scheduler module", "Python Binding", "Reference", "&lt;no title&gt;", "Runtime for WeNet", "How to train models?", "Tutorial on AIShell", "Tutorial on LibriSpeech"], "terms": {"In": [0, 1, 5, 23, 53, 66, 71, 73, 74], "order": [0, 1, 48], "support": [0, 1, 5, 68, 74], "model": [0, 1, 2, 3, 4, 5, 16, 17, 20, 22, 26, 27, 33, 34, 41, 43, 46, 48, 49, 51, 53, 63, 68, 71], "industri": [0, 5, 71], "ten": 0, "million": 0, "hour": [0, 73, 74], "speech": [0, 3, 5, 6, 41, 43, 68, 71, 73, 74], "dataset": [0, 5, 7, 8, 11, 73, 74], "process": [0, 1, 73, 74], "method": [0, 4, 14, 40, 71, 73, 74], "unifi": [0, 5, 48, 52, 71, 74], "ha": [0, 5, 7, 8, 22, 71], "been": [0, 5, 7, 8], "updat": [0, 1, 4, 20], "wenet": [0, 1, 3, 6, 9, 10, 68, 72], "The": [0, 1, 5, 7, 8, 13, 20, 23, 25, 31, 36, 44, 53, 54, 60, 64, 66, 67, 68, 71, 73, 74], "document": 0, "introduc": [0, 68], "from": [0, 1, 5, 20, 22, 23, 41, 43, 53, 64, 71, 73, 74], "follow": [0, 1, 3, 4, 5, 7, 8, 67, 68, 71, 73, 74], "section": [0, 22, 71], "old": [0, 74], "i": [0, 1, 2, 3, 4, 5, 7, 8, 15, 16, 17, 20, 22, 26, 27, 33, 34, 36, 40, 41, 43, 44, 46, 48, 49, 50, 51, 53, 54, 64, 66, 67, 68, 71, 73, 74], "base": [0, 1, 2, 5, 13, 14, 15, 16, 17, 20, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 63, 66, 67, 71, 73, 74], "pytorch": [0, 4, 7, 8, 48, 71], "": [0, 1, 5, 7, 8, 41, 43, 52, 53, 66, 71, 74], "nativ": 0, "dure": [0, 1, 74], "need": [0, 1, 5, 14, 16, 27, 32, 34, 35, 37, 40, 51, 66], "load": [0, 4], "all": [0, 5, 14, 16, 27, 32, 34, 35, 37, 40, 41, 43, 51, 66, 67, 71], "audio": [0, 37, 73, 74], "path": [0, 1, 4, 41, 43, 64, 73, 74], "correspondingli": 0, "label": [0, 1, 22, 53, 60], "memori": [0, 48, 49, 73, 74], "one": [0, 1, 5, 14, 16, 22, 27, 32, 34, 35, 37, 40, 43, 48, 51, 63, 66, 71, 73, 74], "time": [0, 1, 14, 15, 16, 17, 22, 25, 26, 27, 28, 29, 31, 33, 34, 37, 41, 43, 44, 46, 50, 51, 52, 55, 68, 71, 73, 74], "randomli": [0, 23], "read": [0, 64], "case": [0, 44, 66, 71, 74], "grade": 0, "ultra": 0, "larg": [0, 1, 71, 73, 74], "scale": [0, 13, 15, 25, 31, 44], "eg": 0, "more": [0, 3, 6, 71, 73, 74], "than": [0, 22, 66, 71, 73, 74], "50": [0, 22, 23, 73, 74], "000": 0, "thi": [0, 1, 3, 5, 14, 15, 16, 23, 27, 32, 34, 35, 37, 40, 48, 50, 51, 66, 67, 68, 73, 74], "caus": [0, 73, 74], "fail": [0, 1, 4, 71], "run": [0, 14, 32, 34, 35, 37, 40, 73, 74], "two": [0, 4, 5, 7, 8, 20, 71, 73, 74], "reason": [0, 5, 73, 74], "out": [0, 5, 14, 43, 73, 74], "oom": 0, "physic": 0, "gener": [0, 5, 23, 71], "machin": [0, 73, 74], "difficult": 0, "slow": 0, "down": 0, "perform": [0, 1, 14, 32, 34, 35, 37, 40, 60], "cannot": 0, "us": [0, 1, 3, 4, 7, 8, 14, 16, 17, 22, 23, 26, 27, 28, 33, 34, 35, 41, 43, 46, 48, 49, 51, 52, 66, 68, 71], "file": [0, 1, 20, 22, 64, 68, 73, 74], "cach": [0, 13, 14, 16, 17, 25, 26, 27, 28, 31, 33, 34, 40, 41, 43, 44, 46, 48, 49, 51, 52], "speed": [0, 5, 22], "greatli": 0, "reduc": [0, 7, 8, 47], "inspir": 0, "webdataset": 0, "tfrecord": 0, "redesign": 0, "Its": [0, 15, 50], "core": [0, 5], "idea": 0, "make": [0, 16, 27, 34, 51, 66, 71], "multipl": [0, 43, 68], "small": [0, 16, 27, 34, 51, 71], "1000": 0, "piec": [0, 74], "compress": 0, "packet": 0, "tar": [0, 20, 22], "them": [0, 14, 32, 34, 35, 37, 40, 74], "iterabledataset": [0, 20], "advantag": [0, 71], "onli": [0, 1, 5, 15, 16, 26, 27, 33, 34, 46, 48, 49, 50, 51, 66, 71, 74], "index": [0, 2, 60, 74], "inform": [0, 1], "packag": [0, 2, 10], "maintain": [0, 67], "which": [0, 1, 4, 5, 16, 22, 23, 27, 34, 43, 51, 53, 66, 67, 68, 71, 73, 74], "save": [0, 4, 7, 8, 74], "solv": 0, "problem": [0, 1, 73, 74], "fly": [0, 1, 73, 74], "decompress": 0, "same": [0, 1, 5, 16, 22, 34, 36, 41, 43, 51, 54, 66, 67, 68, 73, 74], "sequenc": [0, 5, 36, 47, 53, 54, 60, 66, 71, 73, 74], "random": [0, 16, 27, 51, 66], "differ": [0, 1, 5, 7, 8, 16, 27, 34, 44, 51, 66, 67, 71], "can": [0, 1, 3, 4, 5, 7, 8, 13, 16, 22, 27, 28, 34, 35, 49, 51, 52, 68, 71, 73, 74], "ensur": [0, 4], "global": [0, 20, 73, 74], "new": [0, 1, 13, 16, 34, 41, 43, 51], "take": [0, 14, 16, 27, 32, 34, 35, 37, 40, 51, 73, 74], "account": [0, 16, 27, 34, 51], "both": [0, 5, 66, 71], "provid": [0, 7, 8, 68, 73, 74], "we": [0, 1, 4, 5, 7, 8, 15, 16, 20, 22, 27, 34, 43, 50, 51, 66, 68, 71, 73, 74], "call": [0, 1, 14, 15, 32, 34, 35, 37, 40, 41, 43, 50, 71, 73, 74], "shown": [0, 5, 74], "figur": 0, "below": [0, 5, 64], "some": [0, 1, 16, 27, 34, 51, 53, 73, 74], "necessari": [0, 1, 66], "explan": 0, "about": [0, 73, 74], "abov": [0, 1, 3, 68], "mode": [0, 32, 66, 73, 74], "local": [0, 5, 22, 73, 74], "requir": [0, 3, 4, 5, 7, 8, 15, 16, 27, 34, 41, 43, 50, 51, 68, 71, 73, 74], "must": [0, 17, 28, 52, 73, 74], "sort": [0, 19, 22, 74], "kaldi": [0, 1, 5, 74], "style": [0, 5, 16, 27, 34, 51, 73, 74], "wav": [0, 1, 5, 22, 68], "scp": [0, 5, 73, 74], "text": [0, 1, 5, 22, 41, 43, 73, 74], "It": [0, 1, 5, 71, 73, 74], "befor": [0, 1, 4, 22, 28, 35, 43, 48, 49, 52, 74], "share": [0, 71, 73, 74], "network": [0, 7, 8, 16, 27, 34, 51], "cloud": 0, "storag": 0, "txt": [0, 1, 3, 5, 22, 68, 73, 74], "ar": [0, 1, 5, 8, 16, 23, 27, 34, 36, 51, 53, 54, 68, 71, 73, 74], "store": 0, "singl": [0, 1, 49], "also": [0, 1, 5, 68, 71, 73, 74], "adopt": [0, 1, 71], "implement": [0, 13, 16, 27, 34, 51], "practic": [0, 1, 71], "flexibl": 0, "easier": 0, "expand": [0, 22], "debug": 0, "exampl": [0, 1, 5, 7, 8, 60, 66, 68, 73, 74], "def": 0, "read_dataset": 0, "filenam": 0, "batch_siz": [0, 22, 40, 66, 73, 74], "tf": 0, "tfrecorddataset": 0, "map": [0, 73, 74], "_parse_image_funct": 0, "num_parallel_cal": 0, "experiment": 0, "autotun": 0, "shuffl": [0, 19, 20, 22], "500": [0, 22, 74], "batch": [0, 13, 14, 15, 16, 17, 19, 22, 25, 26, 27, 28, 29, 31, 33, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 60, 66], "drop_remaind": 0, "true": [0, 1, 14, 15, 16, 20, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37, 39, 40, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 66, 68, 73, 74], "repeat": 0, "prefetch": 0, "buffer_s": 0, "return": [0, 1, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 31, 33, 34, 36, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 60, 66], "refer": [0, 2, 4, 14, 68, 73, 74], "dataflow": 0, "includ": [0, 1, 5, 48, 68], "modul": [0, 2, 4, 12, 19, 24, 30, 38, 42, 57, 71], "token": [0, 1, 19, 22, 48, 60], "convert": 0, "specifi": [0, 1, 68, 74], "unit": [0, 1, 5, 14, 22, 36, 48, 54, 68, 73, 74], "char": [0, 5, 22, 73, 74], "bpe": [0, 5, 20, 22, 74], "filter": [0, 19, 22, 37], "unqualifi": 0, "resampl": [0, 19, 22], "option": [0, 3, 5, 17, 22, 23, 66, 68], "comput": [0, 1, 13, 14, 15, 16, 17, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37, 40, 44, 46, 49, 50, 51, 52, 53, 66, 71, 73, 74], "_": [0, 1, 5, 68, 71, 73, 74], "fbank": [0, 22], "featur": [0, 13, 17, 22, 25, 28, 31, 44, 45, 49, 52], "extract": [0, 22], "spec": [0, 22], "augment": [0, 22], "enhanc": 0, "disrupt": 0, "organ": [0, 5, 73, 74], "pad": [0, 16, 17, 19, 22, 26, 27, 28, 32, 33, 40, 43, 44, 46, 47, 48, 51, 52, 53, 60, 66], "what": [0, 4, 5], "There": [0, 5], "sever": [0, 15, 16, 27, 34, 50, 51, 71, 73, 74], "paramet": [0, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 64, 66, 67, 68, 73, 74], "note": [0, 3, 67, 68], "first": [0, 5, 20, 43, 68, 71], "buffer": [0, 22], "size": [0, 7, 8, 13, 14, 15, 16, 17, 22, 25, 26, 27, 28, 31, 33, 34, 35, 37, 41, 43, 44, 46, 48, 49, 50, 51, 52, 53, 55, 66, 71, 73, 74], "recommend": 0, "larger": 0, "number": [0, 13, 16, 22, 23, 25, 27, 31, 36, 44, 48, 51, 53, 54, 66, 67, 73, 74], "contain": [0, 1, 48, 66, 68, 73, 74], "each": [0, 1, 23, 28, 35, 36, 43, 48, 49, 52, 54, 73, 74], "equival": 0, "between": [0, 1, 17, 44, 53, 73], "increas": [0, 15, 50], "you": [0, 3, 4, 5, 7, 8, 68, 71, 73, 74], "set": [0, 16, 23, 27, 41, 43, 51, 66, 71, 73, 74], "1500": 0, "accord": [0, 1, 5, 20, 22], "frame": [0, 1, 5, 22, 47, 71], "oper": [0, 22, 32], "veri": [0, 5, 16, 27, 34, 51, 68, 71], "import": [0, 68], "improv": [0, 1], "dataload": [0, 73], "pre": 0, "granular": 0, "final": [0, 1, 5, 68, 71, 74], "default": [0, 16, 23, 27, 51, 66], "2": [0, 1, 5, 6, 13, 14, 15, 16, 17, 22, 25, 27, 28, 29, 31, 34, 37, 40, 41, 43, 44, 48, 51, 52, 53, 60, 66, 68, 71], "due": 0, "exist": 0, "mai": [0, 1, 5, 66, 73, 74], "alreadi": [0, 43, 73, 74], "so": [0, 5, 15, 22, 43, 50, 60, 68, 71, 73, 74], "real": [0, 66], "when": [0, 1, 4, 22, 44, 66, 68, 71, 73, 74], "insuffici": 0, "next": [0, 1, 16, 27, 34, 41, 43, 51], "fill": 0, "At": 0, "block": [0, 28, 35, 44, 48, 49, 52, 66], "word": [0, 1, 5, 43, 68, 71, 73, 74], "part": [0, 5, 13, 20, 25, 31, 44, 53, 66, 71, 74], "becaus": 0, "previou": [0, 71], "still": 0, "therefor": [0, 5, 71], "avoid": [0, 1, 66, 71], "present": 0, "have": [0, 1, 3, 5, 20, 66, 73, 74], "verifi": 0, "accuraci": [0, 1, 60, 71], "200": [0, 22], "10000": [0, 15, 22, 50], "respect": 0, "cer": 0, "4": [0, 5, 7, 8, 16, 23, 27, 29, 34, 37, 44, 48, 51, 55, 60, 66], "61": 0, "63": 0, "67": 0, "espnet": [0, 13, 74], "similar": [0, 22], "structur": [0, 5, 8, 73, 74], "configur": 0, "thei": [0, 1, 73, 74], "achiev": [0, 71], "recognit": [0, 1, 3, 5, 6, 68, 71, 73, 74], "rate": [0, 13, 15, 16, 22, 23, 25, 27, 28, 29, 31, 34, 35, 36, 44, 48, 49, 50, 51, 52, 53, 54, 55, 67, 71, 73, 74], "show": [0, 5, 71, 73, 74], "correct": 0, "And": [0, 3, 5, 7, 8, 22], "observ": 0, "util": [0, 11, 74], "gpu": [0, 73, 74], "80": [0, 22, 23, 34, 37], "90": 0, "indic": [0, 1, 66, 73], "effici": [0, 17], "high": [0, 67], "For": [0, 5, 7, 8, 15, 50, 68, 71, 73, 74], "detail": [0, 4, 5, 13, 68, 73, 74], "pleas": [0, 3, 5, 7, 68, 71, 73, 74], "http": [0, 3, 4, 5, 7, 8, 13, 14, 15, 22, 25, 31, 40, 44, 50, 68, 74], "github": [0, 3, 5, 13, 68, 73, 74], "com": [0, 3, 5, 13, 68], "e2": [0, 3, 5, 68, 74], "blob": [0, 5, 68], "main": [0, 5, 68], "s0": [0, 73, 74], "sh": [0, 5, 73, 74], "prepar": [0, 5], "three": [0, 16, 27, 34, 51], "relat": [0, 5, 74], "script": [0, 4, 73, 74], "py": [0, 4, 5, 68, 71, 73, 74], "train_data": [0, 74], "cv_data": [0, 74], "test_data": [0, 74], "list": [0, 1, 16, 20, 22, 23, 27, 34, 40, 41, 43, 48, 60, 68, 71, 73, 74], "data_typ": [0, 20, 74], "symbol_t": [0, 20, 22, 43, 74], "python": [0, 2, 4, 7, 8, 69, 71, 74], "bin": [0, 4, 73, 74], "gpu_id": [0, 74], "config": [0, 57, 60, 73, 74], "train_config": [0, 74], "dict": [0, 5, 23, 41, 43, 73, 74], "feat_dir": 0, "train_set": [0, 74], "dev": [0, 74], "If": [0, 1, 3, 4, 25, 31, 44, 49, 66, 68, 73, 74], "type": [0, 4, 13, 14, 15, 16, 17, 20, 25, 26, 27, 28, 29, 31, 33, 34, 35, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 55, 60, 66, 71, 73, 74], "format": [0, 5, 64], "kei": [0, 13, 16, 17, 22, 25, 27, 28, 31, 34, 41, 43, 44, 51, 52, 73, 74], "bac009s0002w0122": [0, 73], "export": [0, 1, 4, 7, 8, 27, 41, 43, 71], "asr": [0, 1, 2, 68, 71, 73, 74], "openslr": [0, 7, 8, 73, 74], "33": [0, 73], "data_aishel": [0, 5, 73], "s0002": [0, 73], "\u800c\u5bf9\u697c\u5e02\u6210\u4ea4\u6291\u5236\u4f5c\u7528\u6700\u5927\u7684\u9650\u8d2d": [0, 73], "bac009s0002w0123": [0, 73], "\u4e5f\u6210\u4e3a\u5730\u65b9\u653f\u5e9c\u7684\u773c\u4e2d\u9489": [0, 73], "bac009s0002w0124": [0, 73], "\u81ea\u516d\u6708\u5e95\u547c\u548c\u6d69\u7279\u5e02\u7387\u5148\u5ba3\u5e03\u53d6\u6d88\u9650\u8d2d\u540e": [0, 73], "line": [0, 1, 22, 73, 74], "json": [0, 22, 73, 74], "serial": 0, "string": 0, "field": [0, 73, 74], "1": [0, 1, 5, 13, 15, 16, 17, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 40, 41, 43, 44, 46, 48, 49, 50, 51, 52, 53, 55, 60, 66, 67, 68, 71], "maryland": 0, "binbinzhang": 0, "code": [0, 1, 4, 5, 7, 8, 71, 74], "s3": 0, "raw_wav": [0, 73], "shards_000000000": 0, "gz": [0, 74], "shards_000000001": 0, "shards_000000002": 0, "oss": 0, "examplebucket": 0, "cn": [0, 7, 8], "hangzhou": 0, "aliyunc": 0, "exampledir": 0, "q1": 0, "how": [0, 1, 2, 4, 71, 73, 74], "distribut": [0, 53], "partit": [0, 20], "rank": [0, 20, 74], "num": [0, 74], "worker": 0, "segment": 0, "class": [0, 5, 13, 14, 15, 16, 17, 20, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 63, 67], "distributedsampl": [0, 19, 20], "__init__": 0, "self": [0, 17, 27, 28, 35, 41, 44, 48, 49, 52, 53], "epoch": [0, 20, 63, 73, 74], "set_epoch": [0, 20], "sampl": [0, 20, 22, 23], "rang": [0, 5, 68], "len": [0, 60, 68], "world_siz": [0, 20, 74], "worker_id": 0, "num_work": [0, 20, 74], "q2": 0, "deal": 0, "unbalanc": 0, "join": [0, 4], "handl": [0, 71], "imbal": 0, "alloc": 0, "applic": [1, 3, 5], "effect": 1, "commonli": 1, "better": [1, 71, 73, 74], "uniqu": 1, "low": 1, "contextu": [1, 68], "inject": 1, "prior": 1, "knowledg": 1, "an": [1, 2, 5, 56, 66, 68, 71, 73, 74], "system": [1, 71, 74], "infer": [1, 27, 40, 71, 73, 74], "user": [1, 7, 8], "favorit": 1, "song": 1, "contact": [1, 5], "app": 1, "locat": 1, "convent": [1, 53], "build": [1, 2, 5, 74], "n": [1, 3, 5, 23, 68, 71, 73, 74], "gram": [1, 5, 74], "finit": 1, "state": [1, 47], "transduc": [1, 11, 60], "fst": [1, 5, 68, 74], "phrase": 1, "compos": [1, 5], "decod": [1, 5, 16, 22, 27, 34, 41, 42, 43, 44, 49, 51, 66, 68, 71, 73, 74], "help": 1, "bia": [1, 26, 32, 33, 40, 46], "result": [1, 7, 8, 16, 27, 34, 41, 43, 51, 66, 68, 71, 73, 74], "toward": 1, "thu": 1, "certain": 1, "scenario": [1, 5, 15, 50, 71], "score": [1, 13, 25, 31, 43, 44, 48, 66, 68, 71], "p": [1, 5, 25, 39, 74], "c": [1, 4, 41, 43, 71, 73, 74], "mathbf": 1, "y": [1, 48, 71], "interpol": 1, "x": [1, 13, 14, 15, 16, 17, 23, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 41, 43, 44, 45, 46, 48, 50, 51, 52, 53, 54, 55, 56, 60, 66, 71, 74], "shallow": 1, "fusion": 1, "mathrm": 1, "arg": [1, 4, 20, 22, 56, 60, 63, 71], "max": [1, 22, 23, 66], "log": [1, 5, 43, 47, 60, 71], "lambda": 1, "where": [1, 13, 16, 25, 27, 29, 31, 34, 41, 43, 44, 51, 55, 71], "tunabl": [1, 73, 74], "hyperparamet": 1, "control": [1, 16, 27, 34, 51, 68], "much": [1, 4, 71], "lm": [1, 2, 3, 9, 68], "influenc": 1, "overal": [1, 71], "want": [1, 3, 4, 73, 74], "cat": [1, 74], "charact": [1, 47, 73], "0": [1, 5, 6, 7, 8, 13, 14, 15, 16, 17, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 40, 41, 43, 44, 46, 47, 48, 50, 51, 52, 53, 55, 60, 66, 67, 68], "25": [1, 22], "construct": [1, 20, 56], "correspond": [1, 5, 7, 8, 15, 43, 50], "match": 1, "reward": 1, "obtain": 1, "artifici": 1, "boost": [1, 73, 74], "earli": 1, "do": [1, 4, 5, 16, 20, 22, 27, 34, 37, 41, 43, 51, 66, 73, 74], "entir": 1, "add": [1, 15, 39, 50, 60, 67], "special": [1, 16, 27, 34, 51], "failur": 1, "arc": 1, "remov": 1, "record": [1, 73, 74], "easili": [1, 71, 73, 74], "determin": 1, "boundari": 1, "hot": 1, "That": 1, "after": [1, 16, 20, 22, 27, 28, 35, 48, 49, 51, 52, 67, 73, 74], "succe": 1, "other": [1, 5, 49, 53, 68, 71, 73, 74], "start": [1, 15, 50, 73, 74], "int": [1, 13, 14, 15, 16, 17, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 66, 67, 68], "contextgraph": 1, "getnextst": 1, "cur_stat": 1, "word_id": 1, "float": [1, 13, 14, 15, 16, 17, 22, 23, 25, 27, 28, 29, 31, 34, 35, 36, 37, 40, 41, 43, 44, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 67, 68], "bool": [1, 13, 14, 15, 16, 17, 20, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 66, 68], "is_start_boundari": 1, "is_end_boundari": 1, "next_stat": 1, "travers": 1, "current": [1, 16, 27, 34, 41, 43, 44, 51, 66, 71], "arciter": 1, "stdfst": 1, "aiter": 1, "graph_": 1, "done": [1, 74], "const": 1, "stdarc": 1, "valu": [1, 13, 16, 17, 23, 25, 27, 28, 31, 34, 40, 41, 43, 44, 48, 51, 52, 53, 60, 66], "ilabel": 1, "backoff": 1, "might": 1, "cover": 1, "weight": [1, 13, 17, 25, 31, 32, 41, 43, 44], "els": [1, 68], "nextstat": 1, "check": [1, 4, 73, 74], "whether": [1, 5, 13, 20, 37, 41, 43, 48, 66, 68], "One": 1, "break": 1, "append": 1, "output": [1, 13, 16, 17, 25, 26, 27, 28, 29, 31, 33, 34, 36, 37, 40, 41, 43, 44, 46, 48, 49, 51, 52, 53, 54, 55, 68, 71, 73, 74], "chang": [1, 5, 23, 71, 73, 74], "function": [1, 4, 5, 14, 15, 23, 32, 34, 35, 36, 37, 40, 50, 54, 56, 60, 66, 73, 74], "end": [1, 2, 5, 6, 68, 71, 73, 74], "posit": [1, 13, 15, 17, 23, 25, 27, 28, 29, 31, 36, 37, 44, 48, 50, 51, 52, 54, 55], "insert": 1, "tag": 1, "bag": 1, "lattic": 1, "faster": [1, 71], "onlin": 1, "modifi": [1, 4, 5, 37], "cc": [1, 5, 7, 8, 71], "tlg": [1, 5, 68, 74], "input": [1, 13, 15, 16, 17, 20, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 40, 41, 43, 44, 46, 48, 49, 50, 51, 52, 54, 55, 66, 71, 73, 74], "decid": 1, "processemit": 1, "processnonemit": 1, "elem": 1, "e_next": 1, "findoraddtoken": 1, "tot_cost": 1, "tok": 1, "null": 1, "begin": [1, 43, 74], "fals": [1, 13, 15, 16, 22, 25, 26, 27, 28, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 46, 48, 49, 50, 51, 52, 53, 68, 73, 74], "context_scor": [1, 68], "context_graph_": 1, "olabel": 1, "val": 1, "context_st": 1, "graph_cost": 1, "forwardlink": 1, "next_tok": 1, "put": [1, 5], "head": [1, 13, 16, 17, 25, 27, 28, 31, 34, 41, 43, 44, 48, 51, 52], "link": [1, 8], "forwardlinkt": 1, "ac_cost": 1, "accumul": [1, 5], "lead": 1, "cost": [1, 71, 73, 74], "too": 1, "void": 1, "latticefasterdecodertpl": 1, "pruneforwardlink": 1, "int32": [1, 60], "frame_plus_on": 1, "extra_costs_chang": 1, "links_prun": 1, "basefloat": 1, "delta": 1, "link_extra_cost": 1, "extra_cost": 1, "acoustic_cost": 1, "bracket": 1, "mean": [1, 13, 16, 17, 25, 26, 27, 28, 31, 33, 34, 41, 43, 44, 45, 46, 51, 52, 53, 64, 66, 68, 73, 74], "link_exta_cost": 1, "best": [1, 5, 41, 43, 68, 71, 73, 74], "through": [1, 73, 74], "sourc": [1, 13, 14, 15, 16, 17, 20, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 60, 61, 63, 64, 66, 67], "destin": 1, "context_path": 1, "split": [1, 5], "symbol": [1, 43, 64, 68, 71, 73, 74], "tabl": [1, 68, 70], "oov": 1, "cd": [1, 3, 68, 73, 74], "home": [1, 73], "runtim": [1, 2, 3, 5, 7, 8, 68], "libtorch": [1, 3, 68, 71, 73, 74], "glog_logtostderr": 1, "glog_v": 1, "wav_path": [1, 73, 74], "docker_resourc": 1, "test": [1, 5], "model_dir": [1, 4, 68, 74], "decoder_main": 1, "chunk_siz": [1, 13, 16, 25, 27, 31, 34, 41, 43, 44, 51, 66], "model_path": 1, "zip": [1, 4, 5, 7, 8, 68, 74], "3": [1, 3, 5, 15, 22, 25, 27, 41, 44, 60, 66, 68, 71], "unit_path": 1, "tee": 1, "tansform": 2, "toolkit": [2, 6, 68], "instal": [2, 73, 74], "prebuilt": 2, "train": [2, 4, 5, 7, 8, 13, 14, 15, 16, 17, 20, 22, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 63, 66, 67, 71], "deploy": 2, "tutori": [2, 72], "librispeech": [2, 5, 7, 8, 72], "aishel": [2, 5, 7, 8, 72], "pretrain": [2, 68, 72, 74], "big": [2, 72, 73, 74], "data": [2, 5, 20, 22, 53, 72], "uio": [2, 72], "product": [2, 4, 5, 6, 13, 25, 31, 44, 68], "context": [2, 9, 13, 16, 25, 26, 27, 31, 33, 34, 44, 46, 51, 66, 68, 71], "bias": [2, 9, 68], "jit": [2, 7, 8, 9, 71], "bind": [2, 69], "paper": [2, 13, 25, 31, 44, 69, 73, 74], "api": [2, 48, 52, 68, 69], "search": [2, 5, 41, 43, 71, 73, 74], "page": 2, "just": [3, 5, 15, 16, 27, 34, 50, 51, 52, 71, 73, 74], "pip": 3, "6": [3, 27, 48, 51, 55, 60, 68], "pip3": [3, 68], "wenetruntim": [3, 68], "see": [3, 4, 5, 7, 8, 15, 41, 44, 50, 66, 71, 73, 74], "doc": [3, 68], "usag": 3, "clone": [3, 68], "repo": 3, "git": [3, 68], "conda": 3, "io": [3, 4], "en": [3, 4, 7, 8, 68, 74], "latest": [3, 4, 16], "miniconda": 3, "html": [3, 4], "creat": [3, 66], "env": 3, "8": [3, 5, 23, 55, 60, 73, 74], "activ": [3, 26, 33, 36, 39, 40, 43, 46, 47, 54, 56, 60, 71], "r": 3, "x86": [3, 7, 8, 71], "languag": [3, 4, 5, 7, 8, 68, 73, 74], "otherwis": [3, 74], "ignor": [3, 14, 32, 34, 35, 37, 40, 53, 60, 66], "step": [3, 40, 48, 66, 67, 73, 74], "cmake": 3, "14": 3, "mkdir": [3, 5, 74], "dgraph_tool": 3, "ON": [3, 74], "platform": 3, "o": [3, 4], "our": [4, 7, 8, 71, 74], "directli": [4, 5, 7, 8, 71], "torch": [4, 13, 14, 15, 16, 17, 25, 26, 27, 28, 29, 31, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 60, 66, 68, 70, 71, 73, 74], "essenti": 4, "deploi": 4, "resourc": [4, 74], "introduct": [4, 71], "TO": [4, 74], "torchscript": [4, 68], "A": [4, 5, 23, 66, 74], "IN": [4, 74], "deep": 4, "dive": 4, "research": [4, 5], "To": [4, 5, 66], "try": [4, 73, 74], "stage": [4, 20, 67], "should": [4, 14, 16, 22, 27, 32, 34, 35, 37, 40, 51, 53, 66, 67, 71], "satisfi": 4, "script_model": 4, "init": [4, 74], "principl": [4, 5], "taken": [4, 16, 27, 34, 51, 53], "consider": 4, "contribut": 4, "especi": [4, 5, 22], "subclass": [4, 14, 32, 34, 35, 37, 40], "nn": [4, 16, 27, 28, 34, 35, 36, 37, 48, 49, 51, 52, 54, 55, 73, 74], "forward": [4, 13, 14, 15, 16, 17, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 71], "know": 4, "allow": [4, 66], "disallow": 4, "tensor": [4, 13, 14, 15, 16, 17, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 60, 66], "unsupport": 4, "attribut": 4, "coverag": 4, "explicit": 4, "possibl": [4, 74], "forc": 4, "typeguard": [4, 70], "readthedoc": 4, "userguid": 4, "statist": [5, 73, 74], "wfst": 5, "framework": [5, 71], "custom": [5, 55, 73, 74], "why": 5, "question": 5, "mani": 5, "peopl": [5, 73, 74], "ask": [5, 73, 74], "now": 5, "rnn": [5, 40], "transform": [5, 11, 13, 16, 25, 27, 31, 34, 41, 60, 71, 73, 74], "full": [5, 16, 27, 41, 43, 51, 66, 74], "swing": 5, "doe": [5, 52, 73, 74], "go": [5, 73, 74], "backward": 5, "simpl": [5, 71, 73, 74], "matur": 5, "complet": 5, "tool": [5, 68, 73, 74], "ani": [5, 64, 73, 74], "amount": 5, "corpu": [5, 74], "fast": [5, 71], "hotfix": 5, "easi": 5, "wide": 5, "actual": [5, 16, 27, 34, 41, 43, 51, 73, 74], "second": [5, 20, 68], "sinc": [5, 7, 8, 14, 32, 34, 35, 37, 40, 71], "work": [5, 16, 27, 34, 51, 66, 71, 73, 74], "hard": 5, "abandon": 5, "tradit": [5, 71], "complex": 5, "technologi": 5, "back": 5, "standard": [5, 17, 53, 71], "power": 5, "solut": 5, "bug": 5, "fix": [5, 16, 27, 41, 43, 51, 66], "replac": 5, "person": 5, "like": [5, 16, 23, 27, 34, 51, 64, 73, 74], "goal": 5, "readi": [5, 68], "prioriti": 5, "draw": 5, "pure": 5, "As": 5, "describ": [5, 40, 71], "choos": 5, "your": [5, 73, 74], "whole": [5, 15, 16, 27, 34, 50, 51, 71, 73, 74], "bellow": 5, "pictur": [5, 71], "wai": [5, 15, 50, 71], "without": [5, 55, 73], "ctc": [5, 41, 42, 43, 71, 73, 74], "prefix": [5, 22, 41, 43, 71, 73, 74], "beam": [5, 41, 43, 71, 73, 74], "With": [5, 71], "graph": 5, "t": [5, 16, 27, 34, 39, 44, 51, 68, 71], "lexicon": [5, 74], "l": [5, 36, 44, 54, 66, 74], "g": [5, 23, 53, 73, 74], "typic": [5, 16, 27, 34, 51, 71, 74], "chines": [5, 7, 68], "english": [5, 20, 22, 68, 74], "its": [5, 66], "\u6211\u4eec": 5, "\u6211": 5, "\u4eec": 5, "appl": 5, "five": 5, "letter": 5, "e": [5, 23, 39, 53, 71, 73, 74], "phonem": 5, "pronunci": 5, "purpos": 5, "name": [5, 73, 74], "compil": 5, "represent": 5, "viterbi": 5, "algorithm": [5, 73, 74], "eas": 5, "keep": [5, 67], "independ": 5, "migrat": 5, "directori": [5, 68, 74], "minim": [5, 22], "remain": 5, "origin": [5, 16, 23, 34, 41, 43, 51, 73, 74], "glog": 5, "meet": [5, 73, 74], "lint": 5, "wrap": 5, "latticefasterdecod": 5, "blank": [5, 41, 60, 73, 74], "skip": [5, 73, 74], "up": [5, 67], "addit": [5, 28, 52, 71], "arpa2fst": 5, "fstdeterminizestar": 5, "fsttablecompos": 5, "fstminimizeencod": 5, "built": 5, "box": 5, "get": [5, 15, 23, 43, 50, 68, 71, 73, 74], "consist": 5, "gain": [5, 23], "10": [5, 22, 43, 60, 74], "aishell2": [5, 7, 8], "here": [5, 7, 8, 16, 27, 34, 41, 43, 51, 52, 71, 73, 74], "dictionari": 5, "7": [5, 41, 60, 73], "unit_fil": [5, 74], "cp": [5, 74], "prepare_dict": [5, 74], "resource_aishel": 5, "filter_scp": 5, "pl": 5, "transcript": [5, 73, 74], "aishell_transcript_v0": 5, "aishell_train_lm": 5, "compile_lexicon_token_fst": [5, 74], "tmp": [5, 74], "lang": [5, 68, 74], "make_tlg": [5, 74], "lang_test": [5, 74], "exit": [5, 74], "nj": [5, 74], "16": [5, 22, 74], "15": [5, 23, 26, 27, 33, 46, 51], "lattice_beam": [5, 74], "5": [5, 16, 17, 34, 37, 41, 43, 60, 66, 67, 68], "max_act": [5, 74], "7000": [5, 74], "blank_skip_thresh": [5, 74], "98": [5, 74], "ctc_weight": [5, 41, 43, 74], "rescoring_weight": [5, 74], "fst_path": [5, 74], "dict_path": [5, 74], "dir": [5, 73, 74], "lm_with_runtim": 5, "orient": 6, "stream": [6, 15, 16, 22, 27, 34, 41, 43, 50, 51, 66, 71], "non": [6, 7, 64, 66, 71, 74], "accept": 6, "interspeech": 6, "2021": 6, "2022": 6, "facilit": [7, 8], "checkpoint": [7, 8, 57, 73, 74], "suffix": [7, 8], "pt": [7, 8, 73, 74], "reproduc": [7, 8], "publish": [7, 8], "continu": [7, 8, 68, 71, 73, 74], "android": [7, 8, 71], "quantiz": [7, 8], "traffic": [7, 8], "BY": [7, 8], "org": [7, 8, 13, 14, 15, 22, 25, 31, 40, 44, 50, 74], "12": [7, 8, 16, 34, 74], "visit": 7, "download": [7, 8, 68], "contributor": [7, 8], "conform": [7, 8, 16, 17, 25, 26, 27, 28, 33, 34, 41, 43, 46, 51, 52, 56, 71, 73, 74], "gigaspeech": [7, 8, 73, 74], "multi_cn": [7, 8], "wenetspeech": [7, 8, 73, 74], "given": [8, 68, 74], "subpackag": 10, "branchform": 11, "submodul": 11, "efficient_conform": 11, "squeezeform": 11, "attent": [12, 15, 16, 17, 24, 27, 28, 30, 34, 35, 41, 42, 43, 48, 49, 50, 51, 52, 66, 71, 73, 74], "multiheadedattent": [12, 13, 25, 28, 31, 35, 42, 44, 49, 52], "relpositionmultiheadedattent": [12, 13, 28, 30, 31, 35, 42, 44, 52], "cgmlp": [12, 17], "convolutionalgatingmlp": [12, 14, 17], "convolutionalspatialgatingunit": [12, 14], "embed": [12, 13, 25, 31, 40, 42, 44], "nopositionalencod": [12, 15, 42, 50], "positionalencod": [12, 15, 42, 48, 50], "relpositionalencod": [12, 15, 42, 50], "scaledpositionalencod": [12, 15, 48], "encod": [12, 13, 15, 17, 24, 25, 28, 29, 30, 31, 35, 37, 41, 42, 43, 44, 48, 49, 50, 52, 55, 66, 71, 73, 74], "branchformerencod": [12, 16], "encoder_lay": [12, 24, 30, 42], "branchformerencoderlay": [12, 17], "test_branchform": 12, "multi": [13, 25, 31, 44, 48, 73, 74], "layer": [13, 16, 17, 25, 27, 28, 29, 31, 34, 35, 36, 40, 44, 48, 49, 51, 52, 54, 55, 71], "definit": [13, 14, 17, 25, 26, 27, 28, 29, 31, 33, 35, 36, 37, 44, 46, 48, 49, 51, 52, 54, 55], "n_head": [13, 25, 31, 40, 44], "n_feat": [13, 25, 31, 44], "dropout_r": [13, 14, 15, 16, 17, 25, 27, 28, 29, 31, 35, 36, 44, 47, 48, 49, 50, 51, 52, 54, 55], "dropout": [13, 15, 17, 25, 28, 29, 31, 34, 35, 36, 40, 44, 48, 49, 50, 52, 54, 55], "queri": [13, 25, 31, 44], "mask": [13, 14, 16, 17, 22, 23, 25, 26, 27, 28, 29, 31, 33, 35, 37, 44, 46, 48, 49, 51, 52, 53, 55, 57], "dot": [13, 25, 31, 44], "time1": [13, 25, 31, 44], "time2": [13, 25, 31, 44], "d_model": [13, 15, 25, 31, 44, 50, 67], "forward_attent": [13, 25, 31, 44], "dtype": [13, 16, 17, 25, 26, 27, 28, 31, 32, 33, 34, 35, 37, 44, 46, 48, 51, 52, 60, 66], "vector": [13, 15, 25, 31, 44, 50], "d_k": [13, 16, 17, 25, 27, 28, 31, 34, 41, 43, 44, 51, 52], "fake": [13, 17, 25, 26, 28, 31, 33, 44, 46, 52], "forward_qkv": [13, 44], "tupl": [13, 14, 15, 16, 17, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 37, 40, 41, 43, 44, 46, 48, 49, 50, 51, 52, 55, 60], "zero_triu": [13, 16, 25, 31, 44], "rel": [13, 15, 25, 31, 44, 50], "found": 13, "pull": 13, "2816": 13, "arxiv": [13, 14, 15, 22, 25, 31, 40, 44, 50], "ab": [13, 14, 15, 22, 25, 31, 44, 50, 74], "1901": [13, 15, 25, 31, 44, 50], "02860": [13, 15, 25, 31, 44, 50], "zero": [13, 15, 32, 40, 50, 66], "upper": 13, "triangular": [13, 25, 31, 44], "matrix": [13, 25, 27, 31, 44], "pos_emb": [13, 14, 17, 25, 28, 31, 35, 44, 52], "cache_t": [13, 25, 26, 31, 33, 44, 46], "num_decoding_left_chunk": [13, 16, 25, 27, 31, 34, 41, 43, 44, 51, 66], "rel_shift": [13, 25, 31, 44], "param": [13, 15, 25, 26, 27, 28, 31, 33, 35, 37, 40, 44, 46, 48, 50, 52, 55, 67], "length": [13, 15, 16, 22, 27, 29, 37, 41, 43, 47, 48, 50, 51, 53, 55, 66], "mlp": 14, "convolut": [14, 16, 17, 24, 27, 28, 29, 30, 34, 35, 37, 42, 51, 52, 55, 66], "gate": 14, "openreview": 14, "net": 14, "forum": 14, "id": [14, 43, 47, 48, 53, 60, 71, 73, 74], "ra": 14, "zvvzlyii": 14, "2105": 14, "08050": 14, "linear_unit": [14, 27, 48, 51], "kernel_s": [14, 26, 32, 33, 37, 46], "use_linear_after_conv": [14, 16], "gate_activ": [14, 16], "str": [14, 16, 17, 20, 22, 26, 27, 32, 33, 34, 39, 40, 41, 43, 46, 48, 51, 60, 66, 68], "defin": [14, 23, 32, 34, 35, 37, 40, 67, 74], "everi": [14, 32, 34, 35, 37, 40, 68, 71], "overridden": [14, 32, 34, 35, 37, 40], "although": [14, 32, 34, 35, 37, 40], "recip": [14, 32, 34, 35, 37, 40, 73, 74], "pass": [14, 32, 34, 35, 37, 40, 44, 49, 66, 67, 71], "within": [14, 32, 34, 35, 37, 40], "instanc": [14, 28, 32, 34, 35, 37, 40, 49, 52], "afterward": [14, 32, 34, 35, 37, 40], "instead": [14, 16, 27, 32, 34, 35, 37, 40, 51], "former": [14, 32, 34, 35, 37, 40], "care": [14, 32, 34, 35, 37, 40], "regist": [14, 32, 34, 35, 37, 40], "hook": [14, 32, 34, 35, 37, 40], "while": [14, 23, 32, 34, 35, 37, 40, 67], "latter": [14, 32, 34, 35, 37, 40], "silent": [14, 32, 34, 35, 37, 40, 74], "causal": [14, 16, 26, 27, 33, 34, 46, 51, 71], "spatial": 14, "csgu": 14, "espnet_initialization_fn": 14, "channel": [14, 26, 33, 37, 46], "gate_add": 14, "yet": 14, "No": [15, 50], "offset": [15, 16, 27, 29, 34, 37, 41, 43, 50, 51, 55], "interfac": [15, 41, 43, 50, 52], "compat": [15, 50, 52], "position_encod": [15, 50, 55], "max_len": [15, 16, 27, 34, 41, 43, 45, 50, 51, 66], "5000": [15, 50, 74], "revers": [15, 50, 60], "dim": [15, 16, 27, 34, 36, 40, 41, 43, 48, 50, 51, 54], "maximum": [15, 22, 50, 67], "pe": [15, 50], "po": [15, 50], "2i": [15, 50], "sin": [15, 50], "dmodel": [15, 50], "co": [15, 50], "shape": [15, 16, 23, 27, 34, 41, 43, 44, 48, 50, 51, 53, 66], "apply_dropout": [15, 50], "fashion": [15, 16, 27, 34, 41, 43, 50, 51], "appli": [15, 20, 22, 23, 43, 44, 47, 48, 50, 53, 66, 73, 74], "onc": [15, 50], "utter": [15, 22, 50, 73, 74], "level": [15, 20, 23, 50, 68, 71], "none": [15, 16, 17, 20, 22, 23, 25, 27, 28, 32, 34, 35, 40, 41, 43, 48, 49, 50, 51, 52, 64, 67], "appendix": [15, 50], "b": [15, 16, 27, 34, 36, 39, 40, 41, 43, 47, 50, 51, 54, 60, 66], "dimens": [15, 17, 28, 29, 35, 37, 48, 49, 50, 52, 55, 74], "sec": 15, "1809": 15, "08895": 15, "reset_paramet": 15, "reset": 15, "input_s": [16, 27, 34, 37, 51], "output_s": [16, 27, 34, 40, 51], "256": [16, 27, 34, 37, 51], "use_attn": 16, "attention_head": [16, 27, 34, 48, 51], "attention_layer_typ": 16, "rel_selfattn": [16, 51], "pos_enc_layer_typ": [16, 27, 34, 51], "rel_po": [16, 27, 34, 51], "rel_pos_typ": 16, "use_cgmlp": 16, "cgmlp_linear_unit": 16, "2048": [16, 27, 48, 51], "cgmlp_conv_kernel": 16, "31": [16, 34], "ident": 16, "merge_method": [16, 17], "concat": [16, 17], "cgmlp_weight": [16, 17], "attn_branch_drop_r": [16, 17], "num_block": [16, 27, 34, 48, 51], "positional_dropout_r": [16, 27, 48, 51], "attention_dropout_r": [16, 27, 34, 51], "input_lay": [16, 27, 48, 51], "conv2d": [16, 27, 30, 51], "padding_idx": [16, 53], "stochastic_depth_r": [16, 17], "static_chunk_s": [16, 27, 34, 51, 66], "use_dynamic_chunk": [16, 27, 34, 51, 66], "global_cmvn": [16, 27, 34, 51, 74], "use_dynamic_left_chunk": [16, 27, 34, 51, 66], "ilen": 16, "decoding_chunk_s": [16, 27, 34, 41, 43, 51, 66, 74], "calcul": [16, 47, 53, 60, 73, 74], "propag": 16, "d": [16, 27, 36, 47, 51, 54, 60, 66, 74], "chunk": [16, 27, 34, 41, 43, 51, 66, 71, 74], "dynam": [16, 22, 27, 34, 41, 43, 51, 66, 74], "left": [16, 26, 27, 33, 34, 43, 46, 48, 51, 66, 71], "subsampl": [16, 24, 27, 30, 34, 41, 42, 43, 51, 71], "subsample_r": [16, 27, 34, 41, 43, 51], "forward_chunk": [16, 27, 34, 51], "required_cache_s": [16, 27, 34, 41, 43, 51], "att_cach": [16, 17, 27, 28, 34, 35, 41, 43, 51, 52], "cnn_cach": [16, 17, 27, 28, 34, 35, 41, 43, 51, 52], "att_mask": [16, 27, 34, 51], "mel": [16, 34, 41, 43, 51], "right_context": [16, 34, 41, 43, 51, 71], "stamp": [16, 27, 34, 41, 43, 51, 71], "compuat": [16, 27, 34, 41, 43, 51], "histori": [16, 27, 34, 40, 41, 43, 51, 71], "elay": [16, 27, 34, 41, 43, 51], "cache_t1": [16, 17, 27, 28, 34, 41, 43, 51, 52], "hidden": [16, 27, 34, 36, 41, 43, 47, 48, 51, 54], "cnn_modul": [16, 27, 34, 41, 43, 51], "cache_t2": [16, 17, 27, 28, 34, 41, 43, 51, 52], "cnn": [16, 27, 34, 41, 43, 51, 71], "lorder": [16, 27, 34, 41, 43, 51], "depend": [16, 34, 41, 43, 51, 66, 68, 73, 74], "forward_chunk_by_chunk": [16, 27, 34, 51], "pai": [16, 27, 34, 51], "thing": [16, 27, 34, 51, 68], "howev": [16, 27, 34, 51, 71], "don": [16, 27, 34, 51], "right": [16, 27, 34, 43, 48, 51, 71], "overlap": [16, 27, 34, 51, 71], "even": [16, 27, 34, 51], "though": [16, 27, 34, 51], "wast": [16, 27, 34, 51], "fraction": [16, 27, 34, 51, 71], "covolut": [16, 27, 34, 51], "tricki": [16, 27, 34, 51], "complic": [16, 27, 34, 51], "sequenti": [16, 27, 34, 51], "stack": [16, 27, 34, 51], "rewrit": [16, 27, 34, 51], "prefer": [16, 27, 34, 51], "attn": [17, 41], "probabl": [17, 23, 41, 53], "learned_av": 17, "fixed_av": 17, "branch": [17, 66], "drop": [17, 22], "stochast": 17, "depth": 17, "mask_pad": [17, 26, 28, 33, 35, 37, 46, 52], "union": 17, "conformerencoderlay": [17, 28, 42, 52], "conv": [17, 28, 37, 52], "cnn_cahc": [17, 28, 52], "datalist": [19, 20], "processor": [19, 20], "kaldi_io": 19, "compute_fbank": [19, 22], "compute_mfcc": [19, 22], "dynamic_batch": [19, 22], "parse_raw": [19, 22], "spec_aug": [19, 22], "spec_sub": [19, 22], "spec_trim": [19, 22], "speed_perturb": [19, 22], "static_batch": [19, 22], "tar_file_and_group": [19, 22], "url_open": [19, 22], "wav_distort": 19, "amp2db": [19, 23], "db2amp": [19, 23], "distort": [19, 23], "distort_chain": [19, 23], "distort_wav_conf": [19, 23], "distort_wav_conf_and_sav": [19, 23], "generate_amp_mask": [19, 23], "make_amp_mask": [19, 23], "make_fence_distort": [19, 23], "make_gain_db": [19, 23], "make_jag_distort": [19, 23], "make_max_distort": [19, 23], "make_poly_distort": [19, 23], "make_quad_distort": [19, 23], "data_list_fil": 20, "conf": [20, 23, 73, 74], "bpe_model": [20, 22], "non_lang_sym": [20, 22], "argument": [20, 28, 35, 49, 52, 67], "shard": [20, 73, 74], "raw": [20, 73, 74], "term": 20, "object": [20, 56, 63], "f": [20, 23, 74], "kw": 20, "batch_typ": 22, "static": [22, 66], "max_frames_in_batch": 22, "12000": 22, "wrapper": 22, "num_mel_bin": 22, "23": 22, "frame_length": 22, "frame_shift": 22, "dither": 22, "iter": 22, "sample_r": 22, "feat": [22, 48], "num_cep": 22, "40": 22, "high_freq": 22, "low_freq": 22, "20": 22, "mfcc": 22, "until": 22, "total": [22, 67, 74], "reach": 22, "max_fram": 22, "max_length": 22, "10240": 22, "min_length": 22, "token_max_length": 22, "token_min_length": 22, "min_output_input_ratio": 22, "0005": 22, "max_output_input_ratio": 22, "inplac": 22, "greater": [22, 66, 73, 74], "10m": 22, "less": [22, 71, 73, 74], "ration": 22, "token_length": 22, "feats_length": 22, "pars": 22, "resample_r": 22, "16000": [22, 68], "target": [22, 53, 60], "shuffle_s": 22, "sort_siz": 22, "group": [22, 32, 71], "utt": 22, "num_t_mask": 22, "num_f_mask": 22, "max_t": 22, "max_f": 22, "max_w": 22, "freq": 22, "width": 22, "warp": 22, "num_t_sub": 22, "substitut": 22, "ref": 22, "u2": [22, 71, 73, 74], "2106": 22, "05642": 22, "trim": 22, "tail": [22, 74], "trimtail": 22, "2211": 22, "00522": 22, "perturb": 22, "open": [22, 68, 74], "content": 22, "src": 22, "split_with_spac": 22, "give": [22, 41, 43, 66, 71], "url": 22, "descriptor": 22, "amp": 23, "db": 23, "func": 23, "waveform": 23, "point": 23, "wavefrom": 23, "distort_typ": 23, "distort_conf": 23, "wav_in": 23, "wav_out": 23, "mask_num": 23, "amplitud": 23, "domain": 23, "100db": 23, "0db": 23, "slot": 23, "100": [23, 74], "65": 23, "60": 23, "30": 23, "db_mask": 23, "fenc": 23, "maxium": 23, "seper": 23, "neget": 23, "mask_numb": 23, "max_db": 23, "could": [23, 44, 66, 73, 74], "jag": 23, "ploynomi": 23, "m": 23, "groupedrelpositionmultiheadedattent": [24, 25], "convolutionmodul": [24, 26, 30, 33, 42, 46], "efficientconformerencod": [24, 27], "strideconformerencoderlay": [24, 28], "conv2dsubsampling2": [24, 29], "group_siz": [25, 27], "2109": [25, 40], "01163": 25, "padding_q": 25, "groupedattent": 25, "effic": 25, "pad4group": 25, "q": 25, "k": [25, 74], "v": [25, 39, 74], "positin": [25, 31, 44], "lower": [25, 31, 44], "relu": [26, 33, 36, 40, 46, 54], "norm": [26, 33, 40, 46], "batch_norm": [26, 27, 33, 34, 46, 51], "stride": [26, 27, 32, 37, 71], "mea": [26, 33, 46], "normalize_befor": [27, 28, 34, 35, 48, 49, 51, 52], "macaron_styl": [27, 51], "activation_typ": [27, 34, 51], "swish": [27, 34, 40, 42, 51], "use_cnn_modul": [27, 51], "cnn_module_kernel": [27, 34, 51], "cnn_module_norm": [27, 51], "stride_layer_idx": 27, "group_layer_idx": 27, "stride_kernel": 27, "kwarg": [27, 56, 67], "calculate_downsampling_factor": [27, 34], "xs_len": [27, 34, 37, 51], "emb": [27, 40, 48, 51], "use_onnx": 27, "simul": 27, "onnx": 27, "set_global_chunk_s": 27, "self_attn": [28, 35, 49, 52], "feed_forward": [28, 49, 52], "feed_forward_macaron": [28, 52], "conv_modul": [28, 35, 52], "pointwise_conv_lay": 28, "feed": [28, 35, 36, 49, 52, 54], "positionwisefeedforward": [28, 30, 35, 36, 37, 42, 49, 52, 54], "convlutionmodul": [28, 35, 52], "layer_norm": [28, 35, 48, 49, 52], "sub": [28, 35, 48, 49, 52], "idim": [29, 36, 37, 54, 55], "odim": [29, 37, 47, 55], "pos_enc_class": [29, 37, 48, 55], "basesubsampl": [29, 37, 42, 55], "2d": [29, 37, 47, 55], "x_mask": [29, 37, 55], "conv2dvalid": [30, 32], "squeezeformerencod": [30, 34], "squeezeformerencoderlay": [30, 35], "positionwise_feed_forward": [30, 42], "depthwiseconv2dsubsampling4": [30, 37], "timereductionlayer1d": [30, 37], "timereductionlayer2d": [30, 37], "timereductionlayerstream": [30, 37], "do_rel_shift": [31, 34], "adaptive_scal": [31, 33, 34, 36], "init_weight": [31, 33, 34, 36, 37], "valid": [32, 63, 73, 74], "in_channel": 32, "out_channel": 32, "dilat": 32, "padding_mod": 32, "devic": [32, 40, 63, 66, 71, 73, 74], "valid_trigx": 32, "valid_trigi": 32, "_convnd": 32, "output_pad": 32, "transpos": 32, "encoder_dim": [34, 37], "reduce_idx": 34, "recover_idx": 34, "11": [34, 60, 74], "feed_forward_expansion_factor": 34, "dw_stride": [34, 37], "input_dropout_r": [34, 37], "time_reduction_layer_typ": 34, "conv1d": 34, "feed_forward_dropout_r": 34, "cnn_norm_typ": 34, "concat_aft": [34, 35], "check_ascending_list": 34, "feed_forward1": 35, "feed_forward2": 35, "positionwis": [36, 54], "hidden_unit": [36, 54], "feedforward": [36, 48, 54], "appi": [36, 54], "dimenst": [36, 54], "timereductionlay": 37, "depthwis": 37, "bank": 37, "out_dim": 37, "nemo": 37, "reduct": 37, "procedur": 37, "downsampl": 37, "multiheadattentionmechan": 37, "kernel": 37, "factor": 37, "joint": [38, 41, 71], "transducerjoint": [38, 39], "predictor": [38, 41, 60], "applypad": [38, 40], "convpredictor": [38, 40], "embeddingpredictor": [38, 40], "predictorbas": [38, 40, 41], "rnnpredictor": [38, 40], "voca_s": [39, 40], "enc_output_s": 39, "pred_output_s": 39, "join_dim": 39, "prejoin_linear": 39, "postjoin_linear": 39, "joint_mod": 39, "tanh": 39, "enc_out": [39, 41], "pred_out": [39, 41], "u": 39, "pad_valu": [40, 60], "max_time_step": 40, "embed_s": 40, "embed_dropout": 40, "history_s": 40, "layer_norm_epsilon": 40, "1e": [40, 67, 74], "05": [40, 53, 67], "batch_to_cach": 40, "history_1": 40, "history_2": 40, "history_3": 40, "new_ach": 40, "cache_to_batch": 40, "history3": 40, "new_caceh": 40, "forward_step": 40, "time_step": 40, "init_st": 40, "pdf": 40, "07513": 40, "proj": 40, "hidden_s": 40, "num_lay": 40, "rnn_type": [40, 60], "lstm": 40, "state_m": 40, "state_c": 40, "n_layer": 40, "state_m_1": 40, "state_c_1": 40, "state_m_2": 40, "state_c_2": 40, "new_cach": 40, "max_tim": 40, "vocab_s": [41, 43, 48, 74], "attention_decod": 41, "transformerdecod": [41, 42, 43, 48], "bitransformerdecod": [41, 42, 48], "ignore_id": [41, 43, 60], "reverse_weight": [41, 43, 48], "lsm_weight": [41, 43], "length_normalized_loss": [41, 43], "transducer_weight": 41, "attention_weight": 41, "asrmodel": [41, 42, 43], "hybrid": [41, 43], "beam_search": 41, "speech_length": [41, 43], "beam_siz": [41, 43, 66, 73, 74], "simulate_stream": [41, 43], "feat_dim": [41, 43, 45], "prohibit": [41, 43], "final_prob": 41, "ctc_prob": 41, "transducer_prob": 41, "text_length": [41, 43], "frontend": [41, 43], "loss": [41, 43, 47, 53, 73, 74], "forward_encoder_chunk": [41, 43, 71], "forward_joint_step": 41, "forward_predictor_init_st": 41, "forward_predictor_step": 41, "greedy_search": 41, "n_step": 41, "64": 41, "greedi": [41, 43, 73, 74], "init_b": 41, "transducer_attention_rescor": 41, "attn_weight": 41, "search_ctc_weight": 41, "search_transducer_weight": 41, "beam_search_typ": 41, "rescor": [41, 43, 71, 73, 74], "rescore_prob": 41, "transducer_loss": 41, "attn_prob": 41, "rnnt": 41, "asr_model": 42, "cmvn": [42, 57], "globalcmvn": [42, 45], "decoder_lay": 42, "decoderlay": [42, 49], "baseencod": [42, 51], "conformerencod": [42, 51], "transformerencod": [42, 43, 51], "transformerencoderlay": [42, 52], "label_smoothing_loss": 42, "labelsmoothingloss": [42, 53], "conv2dsubsampling4": [42, 55], "conv2dsubsampling6": [42, 55], "conv2dsubsampling8": [42, 55], "linearnosubsampl": [42, 55], "lfmmi_dir": 43, "attention_rescor": [43, 73, 74], "nbest": [43, 68], "resor": 43, "ctc_activ": [43, 71], "linear": [43, 55, 71], "softmax": [43, 47, 48, 71], "ctc_greedy_search": [43, 73, 74], "ctc_prefix_beam_search": [43, 73, 74], "eos_symbol": [43, 71], "eo": [43, 60, 66, 71, 73, 74], "calc": 43, "forward_attention_decod": [43, 71], "hyp": [43, 60], "hyps_len": 43, "encoder_out": 43, "hypothesi": 43, "r_hyp": 43, "fo": 43, "verf": 43, "hlg_onebest": 43, "hlg": 43, "hlg_rescor": 43, "lm_scale": 43, "decoder_scal": 43, "r_decoder_scal": 43, "is_bidirectional_decod": 43, "load_hlg_resource_if_necessari": 43, "load_lfmmi_resourc": 43, "recogn": 43, "max_result_len": 43, "sos_symbol": [43, 71], "subsampling_r": [43, 71], "cross": [44, 48, 63, 73, 74], "mocha": 44, "But": [44, 74], "istd": 45, "norm_var": 45, "normal": [45, 53, 73, 74], "encoder_output_s": [47, 48], "argmax": 47, "hs_pad": 47, "3d": 47, "tmax": [47, 60], "eproj": 47, "hlen": 47, "ys_pad": [47, 60], "ys_len": [47, 60], "lmax": [47, 60], "log_softmax": 47, "r_num_block": 48, "self_attention_dropout_r": 48, "src_attention_dropout_r": 48, "use_output_lay": 48, "transfom": 48, "wise": 48, "memory_mask": [48, 49], "ys_in_pad": 48, "ys_in_len": 48, "r_ys_in_pad": 48, "float32": 48, "maxlen_in": [48, 49], "int64": 48, "maxlen_out": [48, 49], "r_x": 48, "olen": 48, "forward_one_step": 48, "tgt": [48, 49], "tgt_mask": [48, 49], "uint8": 48, "max_time_out": 48, "per": 48, "src_attent": 48, "cif": [48, 49], "bidirect": 48, "src_attn": 49, "inter": 49, "gpt": 49, "positon": 50, "abs_po": 51, "positionwise_conv_kernel_s": 51, "selfattention_layer_typ": 51, "smooth": 53, "normalize_length": 53, "ce": 53, "version": [53, 68], "prob": [53, 71], "divid": 53, "among": 53, "9": [53, 60], "flatten": 53, "seqlen": 53, "predict": [53, 60], "signal": 53, "padding_id": 53, "kl": 53, "scalar": 53, "pos_enc": 55, "common": 57, "add_blank": [57, 60], "add_sos_eo": [57, 60], "get_activ": [57, 60], "get_rnn": [57, 60], "get_subsampl": [57, 60], "log_add": [57, 60], "pad_list": [57, 60], "remove_duplicates_and_blank": [57, 60], "replace_duplicates_with_blank": [57, 60], "reverse_pad_list": [57, 60], "th_accuraci": [57, 60], "override_config": [57, 61], "ctc_util": 57, "executor": 57, "file_util": 57, "read_list": [57, 64], "read_non_lang_symbol": [57, 64], "read_symbol_t": [57, 64], "init_model": 57, "add_optional_chunk_mask": [57, 66], "make_non_pad_mask": [57, 66], "make_pad_mask": [57, 66], "mask_finished_pr": [57, 66], "mask_finished_scor": [57, 66], "subsequent_chunk_mask": [57, 66], "subsequent_mask": [57, 66], "schedul": [57, 63], "cosineann": [57, 67], "noamann": [57, 67], "noamholdann": [57, 67], "squareann": [57, 67], "squarerootann": [57, 67], "squarerootconstantpolici": [57, 67], "warmupannealholdpolici": [57, 67], "warmupholdpolici": [57, 67], "warmuplr": [57, 67], "warmuppolici": [57, 67], "unil": 60, "prepad": 60, "ys_in": 60, "eeo": 60, "ys_out": 60, "sos_id": 60, "eos_id": 60, "act": 60, "stabl": [60, 71], "t_1": 60, "t_2": 60, "t_b": 60, "ones": 60, "tokenmax": 60, "seq": 60, "pad_output": 60, "pad_target": 60, "ignore_label": 60, "longtensor": 60, "override_list": 61, "cv": 63, "data_load": 63, "optim": [63, 67, 73, 74], "writer": 63, "scaler": 63, "list_fil": 64, "non_lang_sym_path": 64, "linguist": [64, 74], "nois": 64, "brk": 64, "sym": 64, "symbol_table_fil": 64, "enabl": [66, 68], "pad_mask": 66, "descript": [66, 71], "pred": 66, "flag": 66, "finish": [66, 71, 73, 74], "arrai": 66, "aliv": 66, "aim": 66, "rest": 66, "inf": 66, "num_left_chunk": 66, "cpu": 66, "subsequ": 66, "cuda": [66, 73, 74], "auto": 66, "regress": 66, "fulli": 66, "long": [66, 68, 71], "max_step": 67, "min_lr": 67, "last_epoch": 67, "warmup_step": 67, "warmup_ratio": 67, "_lrschedul": 67, "get_lr": 67, "decay_r": 67, "set_step": 67, "constant_step": 67, "constant_ratio": 67, "warmup": 67, "logic": 67, "lr": 67, "polici": 67, "clariti": 67, "ratio": 67, "infinit": [67, 71], "minimum": 67, "hold": 67, "learn": 67, "decai": 67, "constant": 67, "hold_step": 67, "hold_ratio": 67, "variant": 67, "warm": 67, "25000": 67, "almost": 67, "noamlr": 67, "except": 67, "model_s": 67, "min": [67, 68], "equal": 67, "develop": [68, 71], "timestamp": 68, "align": 68, "phone": 68, "maco": 68, "pack": 68, "window": 68, "linux": 68, "sy": 68, "wav_fil": 68, "argv": 68, "ch": 68, "decode_wav": 68, "print": [68, 74], "offici": 68, "specif": 68, "automat": 68, "md": 68, "top": 68, "enable_timestamp": 68, "bonu": 68, "continuous_decod": 68, "\u4e0d\u5fd8\u521d\u5fc3": 68, "\u7262\u8bb0\u4f7f\u547d": 68, "wave": 68, "test_wav": 68, "rb": 68, "fin": 68, "assert": 68, "getnchannel": 68, "readfram": 68, "getnfram": 68, "suppos": 68, "16k": 68, "16bit": 68, "interv": 68, "last": 68, "chunk_wav": 68, "behavior": 68, "setup": 68, "jinja2": 70, "nbsphinx": 70, "sphinx": 70, "recommonmark": 70, "markdown": 70, "rtd": 70, "theme": 70, "torchaudio": [70, 73], "balanc": 71, "latenc": 71, "accur": 71, "autoregress": 71, "benefit": 71, "find": [71, 73, 74], "form": 71, "usual": 71, "degrad": 71, "lot": 71, "spike": 71, "aspect": 71, "favor": 71, "server": 71, "fed": 71, "further": 71, "partial": 71, "select": 71, "affect": 71, "limit": 71, "promis": 71, "proper": 71, "brief": 71, "increment": 71, "requri": 71, "att": 71, "tircki": 71, "simpli": 71, "straightforward": 71, "neglig": 71, "blue": 71, "color": 71, "vocabulari": [71, 73, 74], "bi": 71, "direct": 71, "recurr": 71, "dnn": 71, "feel": [73, 74], "free": [73, 74], "issu": [73, 74], "thank": [73, 74], "kind": [73, 74], "feedback": [73, 74], "suggest": [73, 74], "manual": [73, 74], "understand": [73, 74], "bash": [73, 74], "stop_stag": [73, 74], "variabl": [73, 74], "absolut": 73, "usernam": 73, "aishell_data_prep": 73, "tab": [73, 74], "separ": [73, 74], "column": [73, 74], "wav_id": [73, 74], "text_label": [73, 74], "bac009s0002w0125": 73, "\u5404\u5730\u653f\u5e9c\u4fbf\u7eb7\u7eb7\u8ddf\u8fdb": 73, "copi": 73, "compute_cmvn_stat": [73, 74], "cepstral": [73, 74], "varianc": [73, 74], "These": [73, 74], "acoust": [73, 74], "integ": [73, 74], "unk": [73, 74], "\u4e00": 73, "\u4e01": 73, "\u9f9a": 73, "4230": 73, "\u9f9f": 73, "4231": 73, "4232": 73, "denot": [73, 74], "unknown": [73, 74], "aslo": [73, 74], "design": [73, 74], "anoth": [73, 74], "10k": [73, 74], "5k": [73, 74], "ddp": [73, 74], "dist_backend": [73, 74], "nccl": [73, 74], "gloo": [73, 74], "visibl": [73, 74], "cuda_visible_devic": [73, 74], "card": [73, 74], "resum": [73, 74], "termin": [73, 74], "accident": [73, 74], "exp": [73, 74], "your_exp": [73, 74], "Then": [73, 74], "yaml": [73, 74], "train_conform": [73, 74], "tensorboard": [73, 74], "2080": [73, 74], "ti": [73, 74], "dai": [73, 74], "monitor": [73, 74], "logdir": [73, 74], "your_exp_nam": [73, 74], "port": [73, 74], "12598": [73, 74], "bind_al": [73, 74], "averag": [73, 74], "average_checkpoint": [73, 74], "average_num": [73, 74], "four": [73, 74], "candid": [73, 74], "higher": [73, 74], "wer": [73, 74], "evalu": [73, 74], "error": [73, 74], "export_jit": [73, 74], "program": 73, "data_url": 74, "www": 74, "datadir": 74, "le": 74, "ge": 74, "echo": 74, "clean": 74, "360": 74, "download_and_untar": 74, "fi": 74, "wave_data": 74, "underscor": 74, "data_prep_torchaudio": 74, "1867": 74, "154075": 74, "0014": 74, "flac": 74, "1970": 74, "26100": 74, "0022": 74, "him": 74, "THAT": 74, "IT": 74, "did": 74, "AT": 74, "task": 74, "yourself": 74, "most": 74, "train_960": 74, "merg": 74, "train_clean_100": 74, "train_clean_360": 74, "train_other_500": 74, "dev_clean": 74, "dev_oth": 74, "in_scp": 74, "out_cmvn": 74, "subset": 74, "lang_char": 74, "bpemod": 74, "nbpe": 74, "_unit": 74, "bpemodel": 74, "borrow": 74, "cut": 74, "spm_train": 74, "model_typ": 74, "model_prefix": 74, "input_sentence_s": 74, "100000000": 74, "spm_encod": 74, "output_format": 74, "tr": 74, "uniq": 74, "awk": 74, "nr": 74, "num_token": 74, "wc": 74, "byte": 74, "pair": 74, "sentencepiec": 74, "4995": 74, "young": 74, "4996": 74, "4997": 74, "youth": 74, "4998": 74, "z": 74, "4999": 74, "zz": 74, "5001": 74, "recog_set": 74, "make_raw_list": 74, "1455": 74, "134435": 74, "0000": 74, "mnt": 74, "nf": 74, "ptm1": 74, "THE": 74, "girl": 74, "who": 74, "came": 74, "INTO": 74, "world": 74, "night": 74, "jess": 74, "ran": 74, "cry": 74, "god": 74, "he": 74, "BE": 74, "son": 74, "had": 74, "grown": 74, "womanhood": 74, "farm": 74, "0001": 74, "AND": 74, "NOT": 74, "angri": 74, "she": 74, "wa": 74, "often": 74, "moros": 74, "winesburg": 74, "said": 74, "drank": 74, "her": 74, "husband": 74, "banker": 74, "0002": 74, "BUT": 74, "louis": 74, "made": 74, "happi": 74, "flew": 74, "half": 74, "insan": 74, "fit": 74, "OF": 74, "temper": 74, "sometim": 74, "noisi": 74, "quarrelsom": 74, "swore": 74, "cri": 74, "anger": 74, "got": 74, "knife": 74, "kitchen": 74, "threaten": 74, "life": 74, "init_fil": 74, "ddp_init": 74, "rm": 74, "delet": 74, "init_method": 74, "readlink": 74, "num_gpu": 74, "cmvn_opt": 74, "write": 74, "later": 74, "pin_memori": 74, "wait": 74, "todo": 74, "decode_checkpoint": 74, "avg_": 74, "average_model": 74, "dst_model": 74, "src_path": 74, "val_best": 74, "poll": 74, "idx": 74, "decode_mod": 74, "test_dir": 74, "penalti": 74, "result_fil": 74, "text_bp": 74, "spm_decod": 74, "input_format": 74, "sed": 74, "eq": 74, "output_fil": 74, "integr": 74, "which_lm": 74, "prune": 74, "arpa": 74, "wget": 74, "unzip": 74, "gunzip": 74, "train_960_unigram5000": 74, "fst_dir": 74, "acoustic_scal": 74, "lm_with_runtime_": 74}, "objects": {"": [[11, 0, 0, "-", "wenet"]], "wenet": [[12, 0, 0, "-", "branchformer"], [19, 0, 0, "-", "dataset"], [24, 0, 0, "-", "efficient_conformer"], [30, 0, 0, "-", "squeezeformer"], [38, 0, 0, "-", "transducer"], [42, 0, 0, "-", "transformer"], [57, 0, 0, "-", "utils"]], "wenet.branchformer": [[13, 0, 0, "-", "attention"], [14, 0, 0, "-", "cgmlp"], [15, 0, 0, "-", "embedding"], [16, 0, 0, "-", "encoder"], [17, 0, 0, "-", "encoder_layer"]], "wenet.branchformer.attention": [[13, 1, 1, "", "MultiHeadedAttention"], [13, 1, 1, "", "RelPositionMultiHeadedAttention"]], "wenet.branchformer.attention.MultiHeadedAttention": [[13, 2, 1, "", "forward"], [13, 2, 1, "", "forward_attention"], [13, 2, 1, "", "forward_qkv"], [13, 3, 1, "", "training"]], "wenet.branchformer.attention.RelPositionMultiHeadedAttention": [[13, 2, 1, "", "forward"], [13, 2, 1, "", "rel_shift"], [13, 3, 1, "", "training"]], "wenet.branchformer.cgmlp": [[14, 1, 1, "", "ConvolutionalGatingMLP"], [14, 1, 1, "", "ConvolutionalSpatialGatingUnit"]], "wenet.branchformer.cgmlp.ConvolutionalGatingMLP": [[14, 2, 1, "", "forward"], [14, 3, 1, "", "training"]], "wenet.branchformer.cgmlp.ConvolutionalSpatialGatingUnit": [[14, 2, 1, "", "espnet_initialization_fn"], [14, 2, 1, "", "forward"], [14, 3, 1, "", "training"]], "wenet.branchformer.embedding": [[15, 1, 1, "", "NoPositionalEncoding"], [15, 1, 1, "", "PositionalEncoding"], [15, 1, 1, "", "RelPositionalEncoding"], [15, 1, 1, "", "ScaledPositionalEncoding"]], "wenet.branchformer.embedding.NoPositionalEncoding": [[15, 2, 1, "", "forward"], [15, 2, 1, "", "position_encoding"], [15, 3, 1, "", "training"]], "wenet.branchformer.embedding.PositionalEncoding": [[15, 2, 1, "", "forward"], [15, 2, 1, "", "position_encoding"], [15, 3, 1, "", "training"]], "wenet.branchformer.embedding.RelPositionalEncoding": [[15, 2, 1, "", "forward"], [15, 3, 1, "", "training"]], "wenet.branchformer.embedding.ScaledPositionalEncoding": [[15, 2, 1, "", "forward"], [15, 2, 1, "", "reset_parameters"], [15, 3, 1, "", "training"]], "wenet.branchformer.encoder": [[16, 1, 1, "", "BranchformerEncoder"]], "wenet.branchformer.encoder.BranchformerEncoder": [[16, 2, 1, "", "forward"], [16, 2, 1, "", "forward_chunk"], [16, 2, 1, "", "forward_chunk_by_chunk"], [16, 2, 1, "", "output_size"], [16, 3, 1, "", "training"]], "wenet.branchformer.encoder_layer": [[17, 1, 1, "", "BranchformerEncoderLayer"]], "wenet.branchformer.encoder_layer.BranchformerEncoderLayer": [[17, 2, 1, "", "forward"], [17, 3, 1, "", "training"]], "wenet.dataset": [[20, 0, 0, "-", "dataset"], [22, 0, 0, "-", "processor"], [23, 0, 0, "-", "wav_distortion"]], "wenet.dataset.dataset": [[20, 1, 1, "", "DataList"], [20, 4, 1, "", "Dataset"], [20, 1, 1, "", "DistributedSampler"], [20, 1, 1, "", "Processor"]], "wenet.dataset.dataset.DataList": [[20, 2, 1, "", "set_epoch"]], "wenet.dataset.dataset.DistributedSampler": [[20, 2, 1, "", "sample"], [20, 2, 1, "", "set_epoch"], [20, 2, 1, "", "update"]], "wenet.dataset.dataset.Processor": [[20, 2, 1, "", "apply"], [20, 2, 1, "", "set_epoch"]], "wenet.dataset.processor": [[22, 4, 1, "", "batch"], [22, 4, 1, "", "compute_fbank"], [22, 4, 1, "", "compute_mfcc"], [22, 4, 1, "", "dynamic_batch"], [22, 4, 1, "", "filter"], [22, 4, 1, "", "padding"], [22, 4, 1, "", "parse_raw"], [22, 4, 1, "", "resample"], [22, 4, 1, "", "shuffle"], [22, 4, 1, "", "sort"], [22, 4, 1, "", "spec_aug"], [22, 4, 1, "", "spec_sub"], [22, 4, 1, "", "spec_trim"], [22, 4, 1, "", "speed_perturb"], [22, 4, 1, "", "static_batch"], [22, 4, 1, "", "tar_file_and_group"], [22, 4, 1, "", "tokenize"], [22, 4, 1, "", "url_opener"]], "wenet.dataset.wav_distortion": [[23, 4, 1, "", "amp2db"], [23, 4, 1, "", "db2amp"], [23, 4, 1, "", "distort"], [23, 4, 1, "", "distort_chain"], [23, 4, 1, "", "distort_wav_conf"], [23, 4, 1, "", "distort_wav_conf_and_save"], [23, 4, 1, "", "generate_amp_mask"], [23, 4, 1, "", "make_amp_mask"], [23, 4, 1, "", "make_fence_distortion"], [23, 4, 1, "", "make_gain_db"], [23, 4, 1, "", "make_jag_distortion"], [23, 4, 1, "", "make_max_distortion"], [23, 4, 1, "", "make_poly_distortion"], [23, 4, 1, "", "make_quad_distortion"]], "wenet.efficient_conformer": [[25, 0, 0, "-", "attention"], [26, 0, 0, "-", "convolution"], [27, 0, 0, "-", "encoder"], [28, 0, 0, "-", "encoder_layer"], [29, 0, 0, "-", "subsampling"]], "wenet.efficient_conformer.attention": [[25, 1, 1, "", "GroupedRelPositionMultiHeadedAttention"]], "wenet.efficient_conformer.attention.GroupedRelPositionMultiHeadedAttention": [[25, 2, 1, "", "forward"], [25, 2, 1, "", "forward_attention"], [25, 2, 1, "", "pad4group"], [25, 2, 1, "", "rel_shift"], [25, 3, 1, "", "training"]], "wenet.efficient_conformer.convolution": [[26, 1, 1, "", "ConvolutionModule"]], "wenet.efficient_conformer.convolution.ConvolutionModule": [[26, 2, 1, "", "forward"], [26, 3, 1, "", "training"]], "wenet.efficient_conformer.encoder": [[27, 1, 1, "", "EfficientConformerEncoder"]], "wenet.efficient_conformer.encoder.EfficientConformerEncoder": [[27, 2, 1, "", "calculate_downsampling_factor"], [27, 2, 1, "", "forward"], [27, 2, 1, "", "forward_chunk"], [27, 2, 1, "", "forward_chunk_by_chunk"], [27, 2, 1, "", "output_size"], [27, 2, 1, "", "set_global_chunk_size"], [27, 3, 1, "", "training"]], "wenet.efficient_conformer.encoder_layer": [[28, 1, 1, "", "StrideConformerEncoderLayer"]], "wenet.efficient_conformer.encoder_layer.StrideConformerEncoderLayer": [[28, 2, 1, "", "forward"], [28, 3, 1, "", "training"]], "wenet.efficient_conformer.subsampling": [[29, 1, 1, "", "Conv2dSubsampling2"]], "wenet.efficient_conformer.subsampling.Conv2dSubsampling2": [[29, 2, 1, "", "forward"], [29, 3, 1, "", "training"]], "wenet.squeezeformer": [[31, 0, 0, "-", "attention"], [32, 0, 0, "-", "conv2d"], [33, 0, 0, "-", "convolution"], [34, 0, 0, "-", "encoder"], [35, 0, 0, "-", "encoder_layer"], [36, 0, 0, "-", "positionwise_feed_forward"], [37, 0, 0, "-", "subsampling"]], "wenet.squeezeformer.attention": [[31, 1, 1, "", "RelPositionMultiHeadedAttention"]], "wenet.squeezeformer.attention.RelPositionMultiHeadedAttention": [[31, 2, 1, "", "forward"], [31, 2, 1, "", "forward_attention"], [31, 2, 1, "", "init_weights"], [31, 2, 1, "", "rel_shift"], [31, 3, 1, "", "training"]], "wenet.squeezeformer.conv2d": [[32, 1, 1, "", "Conv2dValid"]], "wenet.squeezeformer.conv2d.Conv2dValid": [[32, 3, 1, "", "bias"], [32, 3, 1, "", "dilation"], [32, 2, 1, "", "forward"], [32, 3, 1, "", "groups"], [32, 3, 1, "", "in_channels"], [32, 3, 1, "", "kernel_size"], [32, 3, 1, "", "out_channels"], [32, 3, 1, "", "output_padding"], [32, 3, 1, "", "padding"], [32, 3, 1, "", "padding_mode"], [32, 3, 1, "", "stride"], [32, 3, 1, "", "transposed"], [32, 3, 1, "", "weight"]], "wenet.squeezeformer.convolution": [[33, 1, 1, "", "ConvolutionModule"]], "wenet.squeezeformer.convolution.ConvolutionModule": [[33, 2, 1, "", "forward"], [33, 2, 1, "", "init_weights"], [33, 3, 1, "", "training"]], "wenet.squeezeformer.encoder": [[34, 1, 1, "", "SqueezeformerEncoder"]], "wenet.squeezeformer.encoder.SqueezeformerEncoder": [[34, 2, 1, "", "calculate_downsampling_factor"], [34, 2, 1, "", "check_ascending_list"], [34, 2, 1, "", "forward"], [34, 2, 1, "", "forward_chunk"], [34, 2, 1, "", "forward_chunk_by_chunk"], [34, 2, 1, "", "output_size"], [34, 3, 1, "", "training"]], "wenet.squeezeformer.encoder_layer": [[35, 1, 1, "", "SqueezeformerEncoderLayer"]], "wenet.squeezeformer.encoder_layer.SqueezeformerEncoderLayer": [[35, 2, 1, "", "forward"], [35, 3, 1, "", "training"]], "wenet.squeezeformer.positionwise_feed_forward": [[36, 1, 1, "", "PositionwiseFeedForward"]], "wenet.squeezeformer.positionwise_feed_forward.PositionwiseFeedForward": [[36, 2, 1, "", "forward"], [36, 2, 1, "", "init_weights"], [36, 3, 1, "", "training"]], "wenet.squeezeformer.subsampling": [[37, 1, 1, "", "DepthwiseConv2dSubsampling4"], [37, 1, 1, "", "TimeReductionLayer1D"], [37, 1, 1, "", "TimeReductionLayer2D"], [37, 1, 1, "", "TimeReductionLayerStream"]], "wenet.squeezeformer.subsampling.DepthwiseConv2dSubsampling4": [[37, 2, 1, "", "forward"], [37, 3, 1, "", "training"]], "wenet.squeezeformer.subsampling.TimeReductionLayer1D": [[37, 2, 1, "", "forward"], [37, 2, 1, "", "init_weights"], [37, 3, 1, "", "training"]], "wenet.squeezeformer.subsampling.TimeReductionLayer2D": [[37, 2, 1, "", "forward"], [37, 2, 1, "", "init_weights"], [37, 3, 1, "", "training"]], "wenet.squeezeformer.subsampling.TimeReductionLayerStream": [[37, 2, 1, "", "forward"], [37, 2, 1, "", "init_weights"], [37, 3, 1, "", "training"]], "wenet.transducer": [[39, 0, 0, "-", "joint"], [40, 0, 0, "-", "predictor"], [41, 0, 0, "-", "transducer"]], "wenet.transducer.joint": [[39, 1, 1, "", "TransducerJoint"]], "wenet.transducer.joint.TransducerJoint": [[39, 2, 1, "", "forward"], [39, 3, 1, "", "training"]], "wenet.transducer.predictor": [[40, 4, 1, "", "ApplyPadding"], [40, 1, 1, "", "ConvPredictor"], [40, 1, 1, "", "EmbeddingPredictor"], [40, 1, 1, "", "PredictorBase"], [40, 1, 1, "", "RNNPredictor"]], "wenet.transducer.predictor.ConvPredictor": [[40, 2, 1, "", "batch_to_cache"], [40, 2, 1, "", "cache_to_batch"], [40, 2, 1, "", "forward"], [40, 2, 1, "", "forward_step"], [40, 2, 1, "", "init_state"], [40, 3, 1, "", "training"]], "wenet.transducer.predictor.EmbeddingPredictor": [[40, 2, 1, "", "batch_to_cache"], [40, 2, 1, "", "cache_to_batch"], [40, 2, 1, "", "forward"], [40, 2, 1, "", "forward_step"], [40, 2, 1, "", "init_state"], [40, 3, 1, "", "training"]], "wenet.transducer.predictor.PredictorBase": [[40, 2, 1, "", "batch_to_cache"], [40, 2, 1, "", "cache_to_batch"], [40, 2, 1, "", "forward"], [40, 2, 1, "", "forward_step"], [40, 2, 1, "", "init_state"], [40, 3, 1, "", "training"]], "wenet.transducer.predictor.RNNPredictor": [[40, 2, 1, "", "batch_to_cache"], [40, 2, 1, "", "cache_to_batch"], [40, 2, 1, "", "forward"], [40, 2, 1, "", "forward_step"], [40, 2, 1, "", "init_state"], [40, 3, 1, "", "training"]], "wenet.transducer.transducer": [[41, 1, 1, "", "Transducer"]], "wenet.transducer.transducer.Transducer": [[41, 2, 1, "", "beam_search"], [41, 2, 1, "", "forward"], [41, 2, 1, "", "forward_encoder_chunk"], [41, 2, 1, "", "forward_joint_step"], [41, 2, 1, "", "forward_predictor_init_state"], [41, 2, 1, "", "forward_predictor_step"], [41, 2, 1, "", "greedy_search"], [41, 2, 1, "", "init_bs"], [41, 3, 1, "", "training"], [41, 2, 1, "", "transducer_attention_rescoring"]], "wenet.transformer": [[43, 0, 0, "-", "asr_model"], [44, 0, 0, "-", "attention"], [45, 0, 0, "-", "cmvn"], [46, 0, 0, "-", "convolution"], [47, 0, 0, "-", "ctc"], [48, 0, 0, "-", "decoder"], [49, 0, 0, "-", "decoder_layer"], [50, 0, 0, "-", "embedding"], [51, 0, 0, "-", "encoder"], [52, 0, 0, "-", "encoder_layer"], [53, 0, 0, "-", "label_smoothing_loss"], [54, 0, 0, "-", "positionwise_feed_forward"], [55, 0, 0, "-", "subsampling"], [56, 0, 0, "-", "swish"]], "wenet.transformer.asr_model": [[43, 1, 1, "", "ASRModel"]], "wenet.transformer.asr_model.ASRModel": [[43, 2, 1, "", "attention_rescoring"], [43, 2, 1, "", "ctc_activation"], [43, 2, 1, "", "ctc_greedy_search"], [43, 2, 1, "", "ctc_prefix_beam_search"], [43, 2, 1, "", "eos_symbol"], [43, 2, 1, "", "forward"], [43, 2, 1, "", "forward_attention_decoder"], [43, 2, 1, "", "forward_encoder_chunk"], [43, 2, 1, "", "hlg_onebest"], [43, 2, 1, "", "hlg_rescore"], [43, 2, 1, "", "is_bidirectional_decoder"], [43, 2, 1, "", "load_hlg_resource_if_necessary"], [43, 2, 1, "", "load_lfmmi_resource"], [43, 2, 1, "", "recognize"], [43, 2, 1, "", "right_context"], [43, 2, 1, "", "sos_symbol"], [43, 2, 1, "", "subsampling_rate"], [43, 3, 1, "", "training"]], "wenet.transformer.attention": [[44, 1, 1, "", "MultiHeadedAttention"], [44, 1, 1, "", "RelPositionMultiHeadedAttention"]], "wenet.transformer.attention.MultiHeadedAttention": [[44, 2, 1, "", "forward"], [44, 2, 1, "", "forward_attention"], [44, 2, 1, "", "forward_qkv"], [44, 3, 1, "", "training"]], "wenet.transformer.attention.RelPositionMultiHeadedAttention": [[44, 2, 1, "", "forward"], [44, 2, 1, "", "rel_shift"], [44, 3, 1, "", "training"]], "wenet.transformer.cmvn": [[45, 1, 1, "", "GlobalCMVN"]], "wenet.transformer.cmvn.GlobalCMVN": [[45, 2, 1, "", "forward"], [45, 3, 1, "", "training"]], "wenet.transformer.convolution": [[46, 1, 1, "", "ConvolutionModule"]], "wenet.transformer.convolution.ConvolutionModule": [[46, 2, 1, "", "forward"], [46, 3, 1, "", "training"]], "wenet.transformer.ctc": [[47, 1, 1, "", "CTC"]], "wenet.transformer.ctc.CTC": [[47, 2, 1, "", "argmax"], [47, 2, 1, "", "forward"], [47, 2, 1, "", "log_softmax"], [47, 3, 1, "", "training"]], "wenet.transformer.decoder": [[48, 1, 1, "", "BiTransformerDecoder"], [48, 1, 1, "", "TransformerDecoder"]], "wenet.transformer.decoder.BiTransformerDecoder": [[48, 2, 1, "", "forward"], [48, 2, 1, "", "forward_one_step"], [48, 3, 1, "", "training"]], "wenet.transformer.decoder.TransformerDecoder": [[48, 2, 1, "", "forward"], [48, 2, 1, "", "forward_one_step"], [48, 3, 1, "", "training"]], "wenet.transformer.decoder_layer": [[49, 1, 1, "", "DecoderLayer"]], "wenet.transformer.decoder_layer.DecoderLayer": [[49, 2, 1, "", "forward"], [49, 3, 1, "", "training"]], "wenet.transformer.embedding": [[50, 1, 1, "", "NoPositionalEncoding"], [50, 1, 1, "", "PositionalEncoding"], [50, 1, 1, "", "RelPositionalEncoding"]], "wenet.transformer.embedding.NoPositionalEncoding": [[50, 2, 1, "", "forward"], [50, 2, 1, "", "position_encoding"], [50, 3, 1, "", "training"]], "wenet.transformer.embedding.PositionalEncoding": [[50, 2, 1, "", "forward"], [50, 2, 1, "", "position_encoding"], [50, 3, 1, "", "training"]], "wenet.transformer.embedding.RelPositionalEncoding": [[50, 2, 1, "", "forward"], [50, 3, 1, "", "training"]], "wenet.transformer.encoder": [[51, 1, 1, "", "BaseEncoder"], [51, 1, 1, "", "ConformerEncoder"], [51, 1, 1, "", "TransformerEncoder"]], "wenet.transformer.encoder.BaseEncoder": [[51, 2, 1, "", "forward"], [51, 2, 1, "", "forward_chunk"], [51, 2, 1, "", "forward_chunk_by_chunk"], [51, 2, 1, "", "output_size"], [51, 3, 1, "", "training"]], "wenet.transformer.encoder.ConformerEncoder": [[51, 3, 1, "", "training"]], "wenet.transformer.encoder.TransformerEncoder": [[51, 3, 1, "", "training"]], "wenet.transformer.encoder_layer": [[52, 1, 1, "", "ConformerEncoderLayer"], [52, 1, 1, "", "TransformerEncoderLayer"]], "wenet.transformer.encoder_layer.ConformerEncoderLayer": [[52, 2, 1, "", "forward"], [52, 3, 1, "", "training"]], "wenet.transformer.encoder_layer.TransformerEncoderLayer": [[52, 2, 1, "", "forward"], [52, 3, 1, "", "training"]], "wenet.transformer.label_smoothing_loss": [[53, 1, 1, "", "LabelSmoothingLoss"]], "wenet.transformer.label_smoothing_loss.LabelSmoothingLoss": [[53, 2, 1, "", "forward"], [53, 3, 1, "", "training"]], "wenet.transformer.positionwise_feed_forward": [[54, 1, 1, "", "PositionwiseFeedForward"]], "wenet.transformer.positionwise_feed_forward.PositionwiseFeedForward": [[54, 2, 1, "", "forward"], [54, 3, 1, "", "training"]], "wenet.transformer.subsampling": [[55, 1, 1, "", "BaseSubsampling"], [55, 1, 1, "", "Conv2dSubsampling4"], [55, 1, 1, "", "Conv2dSubsampling6"], [55, 1, 1, "", "Conv2dSubsampling8"], [55, 1, 1, "", "LinearNoSubsampling"]], "wenet.transformer.subsampling.BaseSubsampling": [[55, 2, 1, "", "position_encoding"], [55, 3, 1, "", "training"]], "wenet.transformer.subsampling.Conv2dSubsampling4": [[55, 2, 1, "", "forward"], [55, 3, 1, "", "training"]], "wenet.transformer.subsampling.Conv2dSubsampling6": [[55, 2, 1, "", "forward"], [55, 3, 1, "", "training"]], "wenet.transformer.subsampling.Conv2dSubsampling8": [[55, 2, 1, "", "forward"], [55, 3, 1, "", "training"]], "wenet.transformer.subsampling.LinearNoSubsampling": [[55, 2, 1, "", "forward"], [55, 3, 1, "", "training"]], "wenet.transformer.swish": [[56, 1, 1, "", "Swish"]], "wenet.transformer.swish.Swish": [[56, 2, 1, "", "forward"], [56, 3, 1, "", "training"]], "wenet.utils": [[60, 0, 0, "-", "common"], [61, 0, 0, "-", "config"], [63, 0, 0, "-", "executor"], [64, 0, 0, "-", "file_utils"], [66, 0, 0, "-", "mask"], [67, 0, 0, "-", "scheduler"]], "wenet.utils.common": [[60, 4, 1, "", "add_blank"], [60, 4, 1, "", "add_sos_eos"], [60, 4, 1, "", "get_activation"], [60, 4, 1, "", "get_rnn"], [60, 4, 1, "", "get_subsample"], [60, 4, 1, "", "log_add"], [60, 4, 1, "", "pad_list"], [60, 4, 1, "", "remove_duplicates_and_blank"], [60, 4, 1, "", "replace_duplicates_with_blank"], [60, 4, 1, "", "reverse_pad_list"], [60, 4, 1, "", "th_accuracy"]], "wenet.utils.config": [[61, 4, 1, "", "override_config"]], "wenet.utils.executor": [[63, 1, 1, "", "Executor"]], "wenet.utils.executor.Executor": [[63, 2, 1, "", "cv"], [63, 2, 1, "", "train"]], "wenet.utils.file_utils": [[64, 4, 1, "", "read_lists"], [64, 4, 1, "", "read_non_lang_symbols"], [64, 4, 1, "", "read_symbol_table"]], "wenet.utils.mask": [[66, 4, 1, "", "add_optional_chunk_mask"], [66, 4, 1, "", "make_non_pad_mask"], [66, 4, 1, "", "make_pad_mask"], [66, 4, 1, "", "mask_finished_preds"], [66, 4, 1, "", "mask_finished_scores"], [66, 4, 1, "", "subsequent_chunk_mask"], [66, 4, 1, "", "subsequent_mask"]], "wenet.utils.scheduler": [[67, 1, 1, "", "CosineAnnealing"], [67, 1, 1, "", "NoamAnnealing"], [67, 1, 1, "", "NoamHoldAnnealing"], [67, 1, 1, "", "SquareAnnealing"], [67, 1, 1, "", "SquareRootAnnealing"], [67, 1, 1, "", "SquareRootConstantPolicy"], [67, 1, 1, "", "WarmupAnnealHoldPolicy"], [67, 1, 1, "", "WarmupHoldPolicy"], [67, 1, 1, "", "WarmupLR"], [67, 1, 1, "", "WarmupPolicy"]], "wenet.utils.scheduler.NoamAnnealing": [[67, 2, 1, "", "get_lr"]], "wenet.utils.scheduler.NoamHoldAnnealing": [[67, 2, 1, "", "set_step"]], "wenet.utils.scheduler.SquareRootConstantPolicy": [[67, 2, 1, "", "get_lr"]], "wenet.utils.scheduler.WarmupAnnealHoldPolicy": [[67, 2, 1, "", "get_lr"]], "wenet.utils.scheduler.WarmupHoldPolicy": [[67, 2, 1, "", "get_lr"]], "wenet.utils.scheduler.WarmupLR": [[67, 2, 1, "", "get_lr"], [67, 2, 1, "", "set_step"]], "wenet.utils.scheduler.WarmupPolicy": [[67, 2, 1, "", "get_lr"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method", "3": "py:attribute", "4": "py:function"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "method", "Python method"], "3": ["py", "attribute", "Python attribute"], "4": ["py", "function", "Python function"]}, "titleterms": {"big": 0, "data": [0, 73, 74], "train": [0, 3, 72, 73, 74], "uio": 0, "necess": 0, "upgrad": 0, "io": 0, "mothod": 0, "system": [0, 5], "design": [0, 5, 71], "overal": 0, "chain": 0, "valid": 0, "experi": [0, 73, 74], "aishel": [0, 73], "raw": 0, "v": 0, "shard": 0, "wenetspeech": 0, "usag": [0, 1, 68], "q": 0, "A": 0, "context": 1, "bias": 1, "graph": 1, "ctc": [1, 47], "prefix": 1, "beam": 1, "search": 1, "wfst": 1, "prune": 1, "welcom": 2, "wenet": [2, 4, 5, 7, 8, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 71, 73, 74], "": 2, "document": 2, "content": [2, 9, 69, 72], "indic": 2, "tabl": 2, "instal": [3, 68], "prebuilt": 3, "python": [3, 10, 68], "packag": [3, 11, 12, 19, 24, 30, 38, 42, 57], "build": [3, 68], "deploy": 3, "jit": 4, "lm": [5, 74], "motiv": 5, "implement": [5, 71], "result": 5, "how": [5, 72], "us": [5, 73, 74], "paper": 6, "pretrain": [7, 8], "model": [7, 8, 72, 73, 74], "type": [7, 8], "licens": [7, 8], "list": [7, 8], "product": 9, "runtim": [9, 71, 74], "api": 10, "refer": [10, 69, 71], "subpackag": 11, "branchform": [12, 13, 14, 15, 16, 17, 18], "submodul": [12, 19, 24, 30, 38, 42, 57], "attent": [13, 25, 31, 44], "modul": [13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 29, 31, 32, 33, 34, 35, 36, 37, 39, 40, 41, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67], "cgmlp": 14, "embed": [15, 50], "encod": [16, 27, 34, 51], "encoder_lay": [17, 28, 35, 52], "test_branchform": 18, "dataset": [19, 20, 21, 22, 23], "kaldi_io": 21, "processor": 22, "wav_distort": 23, "efficient_conform": [24, 25, 26, 27, 28, 29], "convolut": [26, 33, 46], "subsampl": [29, 37, 55], "squeezeform": [30, 31, 32, 33, 34, 35, 36, 37], "conv2d": 32, "positionwise_feed_forward": [36, 54], "transduc": [38, 39, 40, 41], "joint": 39, "predictor": 40, "transform": [42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56], "asr_model": 43, "cmvn": [45, 59, 73, 74], "decod": 48, "decoder_lay": 49, "label_smoothing_loss": 53, "swish": 56, "util": [57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67], "checkpoint": 58, "common": 60, "config": 61, "ctc_util": 62, "executor": 63, "file_util": 64, "init_model": 65, "mask": 66, "schedul": 67, "bind": 68, "non": 68, "stream": 68, "your": 68, "local": 68, "machin": 68, "platform": 71, "support": 71, "architectur": 71, "interfac": 71, "cach": 71, "detail": 71, "tutori": [73, 74], "setup": [73, 74], "environ": [73, 74], "first": [73, 74], "stage": [73, 74], "1": [73, 74], "download": [73, 74], "0": [73, 74], "prepar": [73, 74], "extract": [73, 74], "optin": [73, 74], "featur": [73, 74], "2": [73, 74], "gener": [73, 74], "label": [73, 74], "token": [73, 74], "dictionari": [73, 74], "3": [73, 74], "format": [73, 74], "4": [73, 74], "neural": [73, 74], "network": [73, 74], "5": [73, 74], "recogn": [73, 74], "wav": [73, 74], "6": [73, 74], "export": [73, 74], "librispeech": 74, "option": 74, "7": 74, "add": 74, "test": 74}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "nbsphinx": 4, "sphinx.ext.viewcode": 1, "sphinx.ext.todo": 2, "sphinx": 57}, "alltitles": {"Big Data Training: UIO": [[0, "big-data-training-uio"]], "Necessity of upgrading IO mothod": [[0, "necessity-of-upgrading-io-mothod"]], "System design of UIO": [[0, "system-design-of-uio"]], "Overall design": [[0, "overall-design"]], "Chain IO": [[0, "chain-io"]], "Validation experiments": [[0, "validation-experiments"]], "Aishell(raw vs shard)": [[0, "aishell-raw-vs-shard"]], "WenetSpeech(shard)": [[0, "wenetspeech-shard"]], "Usage of UIO": [[0, "usage-of-uio"]], "Q&A": [[0, "q-a"]], "Context Biasing": [[1, "context-biasing"]], "Context Graph": [[1, "context-graph"]], "CTC Prefix Beam Search": [[1, "ctc-prefix-beam-search"]], "CTC WFST Beam Search": [[1, "ctc-wfst-beam-search"]], "Pruning": [[1, "pruning"]], "Usage": [[1, "usage"], [68, "usage"]], "Welcome to wenet\u2019s documentation!": [[2, "welcome-to-wenet-s-documentation"]], "Contents:": [[2, null], [9, null], [69, null], [72, null]], "Indices and tables": [[2, "indices-and-tables"]], "Install": [[3, "install"], [68, "install"]], "Install prebuilt python package": [[3, "install-prebuilt-python-package"]], "Install for training": [[3, "install-for-training"]], "Build for deployment": [[3, "build-for-deployment"]], "JIT in WeNet": [[4, "jit-in-wenet"]], "LM for WeNet": [[5, "lm-for-wenet"]], "Motivation": [[5, "motivation"]], "System Design": [[5, "system-design"]], "Implementation": [[5, "implementation"]], "Results": [[5, "results"]], "How to use?": [[5, "how-to-use"]], "Papers": [[6, "papers"]], "Pretrained Models in WeNet": [[7, "pretrained-models-in-wenet"], [8, "pretrained-models-in-wenet"]], "Model Types": [[7, "model-types"], [8, "model-types"]], "Model License": [[7, "model-license"], [8, "model-license"]], "Model List": [[7, "model-list"], [8, "model-list"]], "Production Runtime": [[9, "production-runtime"]], "Python API Reference": [[10, "python-api-reference"]], "wenet package": [[11, "module-wenet"]], "Subpackages": [[11, "subpackages"]], "wenet.branchformer package": [[12, "module-wenet.branchformer"]], "Submodules": [[12, "submodules"], [19, "submodules"], [24, "submodules"], [30, "submodules"], [38, "submodules"], [42, "submodules"], [57, "submodules"]], "wenet.branchformer.attention module": [[13, "module-wenet.branchformer.attention"]], "wenet.branchformer.cgmlp module": [[14, "module-wenet.branchformer.cgmlp"]], "wenet.branchformer.embedding module": [[15, "module-wenet.branchformer.embedding"]], "wenet.branchformer.encoder module": [[16, "module-wenet.branchformer.encoder"]], "wenet.branchformer.encoder_layer module": [[17, "module-wenet.branchformer.encoder_layer"]], "wenet.branchformer.test_branchformer module": [[18, "wenet-branchformer-test-branchformer-module"]], "wenet.dataset package": [[19, "module-wenet.dataset"]], "wenet.dataset.dataset module": [[20, "module-wenet.dataset.dataset"]], "wenet.dataset.kaldi_io module": [[21, "wenet-dataset-kaldi-io-module"]], "wenet.dataset.processor module": [[22, "module-wenet.dataset.processor"]], "wenet.dataset.wav_distortion module": [[23, "module-wenet.dataset.wav_distortion"]], "wenet.efficient_conformer package": [[24, "module-wenet.efficient_conformer"]], "wenet.efficient_conformer.attention module": [[25, "module-wenet.efficient_conformer.attention"]], "wenet.efficient_conformer.convolution module": [[26, "module-wenet.efficient_conformer.convolution"]], "wenet.efficient_conformer.encoder module": [[27, "module-wenet.efficient_conformer.encoder"]], "wenet.efficient_conformer.encoder_layer module": [[28, "module-wenet.efficient_conformer.encoder_layer"]], "wenet.efficient_conformer.subsampling module": [[29, "module-wenet.efficient_conformer.subsampling"]], "wenet.squeezeformer package": [[30, "module-wenet.squeezeformer"]], "wenet.squeezeformer.attention module": [[31, "module-wenet.squeezeformer.attention"]], "wenet.squeezeformer.conv2d module": [[32, "module-wenet.squeezeformer.conv2d"]], "wenet.squeezeformer.convolution module": [[33, "module-wenet.squeezeformer.convolution"]], "wenet.squeezeformer.encoder module": [[34, "module-wenet.squeezeformer.encoder"]], "wenet.squeezeformer.encoder_layer module": [[35, "module-wenet.squeezeformer.encoder_layer"]], "wenet.squeezeformer.positionwise_feed_forward module": [[36, "module-wenet.squeezeformer.positionwise_feed_forward"]], "wenet.squeezeformer.subsampling module": [[37, "module-wenet.squeezeformer.subsampling"]], "wenet.transducer package": [[38, "module-wenet.transducer"]], "wenet.transducer.joint module": [[39, "module-wenet.transducer.joint"]], "wenet.transducer.predictor module": [[40, "module-wenet.transducer.predictor"]], "wenet.transducer.transducer module": [[41, "module-wenet.transducer.transducer"]], "wenet.transformer package": [[42, "module-wenet.transformer"]], "wenet.transformer.asr_model module": [[43, "module-wenet.transformer.asr_model"]], "wenet.transformer.attention module": [[44, "module-wenet.transformer.attention"]], "wenet.transformer.cmvn module": [[45, "module-wenet.transformer.cmvn"]], "wenet.transformer.convolution module": [[46, "module-wenet.transformer.convolution"]], "wenet.transformer.ctc module": [[47, "module-wenet.transformer.ctc"]], "wenet.transformer.decoder module": [[48, "module-wenet.transformer.decoder"]], "wenet.transformer.decoder_layer module": [[49, "module-wenet.transformer.decoder_layer"]], "wenet.transformer.embedding module": [[50, "module-wenet.transformer.embedding"]], "wenet.transformer.encoder module": [[51, "module-wenet.transformer.encoder"]], "wenet.transformer.encoder_layer module": [[52, "module-wenet.transformer.encoder_layer"]], "wenet.transformer.label_smoothing_loss module": [[53, "module-wenet.transformer.label_smoothing_loss"]], "wenet.transformer.positionwise_feed_forward module": [[54, "module-wenet.transformer.positionwise_feed_forward"]], "wenet.transformer.subsampling module": [[55, "module-wenet.transformer.subsampling"]], "wenet.transformer.swish module": [[56, "module-wenet.transformer.swish"]], "wenet.utils package": [[57, "module-wenet.utils"]], "wenet.utils.checkpoint module": [[58, "wenet-utils-checkpoint-module"]], "wenet.utils.cmvn module": [[59, "wenet-utils-cmvn-module"]], "wenet.utils.common module": [[60, "module-wenet.utils.common"]], "wenet.utils.config module": [[61, "module-wenet.utils.config"]], "wenet.utils.ctc_util module": [[62, "wenet-utils-ctc-util-module"]], "wenet.utils.executor module": [[63, "module-wenet.utils.executor"]], "wenet.utils.file_utils module": [[64, "module-wenet.utils.file_utils"]], "wenet.utils.init_model module": [[65, "wenet-utils-init-model-module"]], "wenet.utils.mask module": [[66, "module-wenet.utils.mask"]], "wenet.utils.scheduler module": [[67, "module-wenet.utils.scheduler"]], "Python Binding": [[68, "python-binding"]], "Non-streaming Usage": [[68, "non-streaming-usage"]], "Streaming Usage": [[68, "streaming-usage"]], "Build on Your Local Machine": [[68, "build-on-your-local-machine"]], "Reference": [[69, "reference"]], "Runtime for WeNet": [[71, "runtime-for-wenet"]], "Platforms Supported": [[71, "platforms-supported"]], "Architecture and Implementation": [[71, "architecture-and-implementation"]], "Architecture": [[71, "architecture"]], "Interface Design": [[71, "interface-design"]], "Cache in Details": [[71, "cache-in-details"]], "References": [[71, "references"]], "How to train models?": [[72, "how-to-train-models"]], "Tutorial on AIShell": [[73, "tutorial-on-aishell"]], "Setup environment": [[73, "setup-environment"], [74, "setup-environment"]], "First Experiment": [[73, "first-experiment"], [74, "first-experiment"]], "Stage -1: Download data": [[73, "stage-1-download-data"], [74, "stage-1-download-data"]], "Stage 0: Prepare Training data": [[73, "stage-0-prepare-training-data"], [74, "stage-0-prepare-training-data"]], "Stage 1: Extract optinal cmvn features": [[73, "stage-1-extract-optinal-cmvn-features"], [74, "stage-1-extract-optinal-cmvn-features"]], "Stage 2: Generate label token dictionary": [[73, "stage-2-generate-label-token-dictionary"], [74, "stage-2-generate-label-token-dictionary"]], "Stage 3: Prepare WeNet data format": [[73, "stage-3-prepare-wenet-data-format"], [74, "stage-3-prepare-wenet-data-format"]], "Stage 4: Neural Network training": [[73, "stage-4-neural-network-training"], [74, "stage-4-neural-network-training"]], "Stage 5: Recognize wav using the trained model": [[73, "stage-5-recognize-wav-using-the-trained-model"], [74, "stage-5-recognize-wav-using-the-trained-model"]], "Stage 6: Export the trained model": [[73, "stage-6-export-the-trained-model"]], "Tutorial on LibriSpeech": [[74, "tutorial-on-librispeech"]], "Stage 6(Optional): Export the trained model": [[74, "stage-6-optional-export-the-trained-model"]], "Stage 7(Optional): Add LM and test it with runtime": [[74, "stage-7-optional-add-lm-and-test-it-with-runtime"]]}, "indexentries": {"module": [[11, "module-wenet"], [12, "module-wenet.branchformer"], [13, "module-wenet.branchformer.attention"], [14, "module-wenet.branchformer.cgmlp"], [15, "module-wenet.branchformer.embedding"], [16, "module-wenet.branchformer.encoder"], [17, "module-wenet.branchformer.encoder_layer"], [19, "module-wenet.dataset"], [20, "module-wenet.dataset.dataset"], [22, "module-wenet.dataset.processor"], [23, "module-wenet.dataset.wav_distortion"], [24, "module-wenet.efficient_conformer"], [25, "module-wenet.efficient_conformer.attention"], [26, "module-wenet.efficient_conformer.convolution"], [27, "module-wenet.efficient_conformer.encoder"], [28, "module-wenet.efficient_conformer.encoder_layer"], [29, "module-wenet.efficient_conformer.subsampling"], [30, "module-wenet.squeezeformer"], [31, "module-wenet.squeezeformer.attention"], [32, "module-wenet.squeezeformer.conv2d"], [33, "module-wenet.squeezeformer.convolution"], [34, "module-wenet.squeezeformer.encoder"], [35, "module-wenet.squeezeformer.encoder_layer"], [36, "module-wenet.squeezeformer.positionwise_feed_forward"], [37, "module-wenet.squeezeformer.subsampling"], [38, "module-wenet.transducer"], [39, "module-wenet.transducer.joint"], [40, "module-wenet.transducer.predictor"], [41, "module-wenet.transducer.transducer"], [42, "module-wenet.transformer"], [43, "module-wenet.transformer.asr_model"], [44, "module-wenet.transformer.attention"], [45, "module-wenet.transformer.cmvn"], [46, "module-wenet.transformer.convolution"], [47, "module-wenet.transformer.ctc"], [48, "module-wenet.transformer.decoder"], [49, "module-wenet.transformer.decoder_layer"], [50, "module-wenet.transformer.embedding"], [51, "module-wenet.transformer.encoder"], [52, "module-wenet.transformer.encoder_layer"], [53, "module-wenet.transformer.label_smoothing_loss"], [54, "module-wenet.transformer.positionwise_feed_forward"], [55, "module-wenet.transformer.subsampling"], [56, "module-wenet.transformer.swish"], [57, "module-wenet.utils"], [60, "module-wenet.utils.common"], [61, "module-wenet.utils.config"], [63, "module-wenet.utils.executor"], [64, "module-wenet.utils.file_utils"], [66, "module-wenet.utils.mask"], [67, "module-wenet.utils.scheduler"]], "wenet": [[11, "module-wenet"]], "wenet.branchformer": [[12, "module-wenet.branchformer"]], "multiheadedattention (class in wenet.branchformer.attention)": [[13, "wenet.branchformer.attention.MultiHeadedAttention"]], "relpositionmultiheadedattention (class in wenet.branchformer.attention)": [[13, "wenet.branchformer.attention.RelPositionMultiHeadedAttention"]], "forward() (wenet.branchformer.attention.multiheadedattention method)": [[13, "wenet.branchformer.attention.MultiHeadedAttention.forward"]], "forward() (wenet.branchformer.attention.relpositionmultiheadedattention method)": [[13, "wenet.branchformer.attention.RelPositionMultiHeadedAttention.forward"]], "forward_attention() (wenet.branchformer.attention.multiheadedattention method)": [[13, "wenet.branchformer.attention.MultiHeadedAttention.forward_attention"]], "forward_qkv() (wenet.branchformer.attention.multiheadedattention method)": [[13, "wenet.branchformer.attention.MultiHeadedAttention.forward_qkv"]], "rel_shift() (wenet.branchformer.attention.relpositionmultiheadedattention method)": [[13, "wenet.branchformer.attention.RelPositionMultiHeadedAttention.rel_shift"]], "training (wenet.branchformer.attention.multiheadedattention attribute)": [[13, "wenet.branchformer.attention.MultiHeadedAttention.training"]], "training (wenet.branchformer.attention.relpositionmultiheadedattention attribute)": [[13, "wenet.branchformer.attention.RelPositionMultiHeadedAttention.training"]], "wenet.branchformer.attention": [[13, "module-wenet.branchformer.attention"]], "convolutionalgatingmlp (class in wenet.branchformer.cgmlp)": [[14, "wenet.branchformer.cgmlp.ConvolutionalGatingMLP"]], "convolutionalspatialgatingunit (class in wenet.branchformer.cgmlp)": [[14, "wenet.branchformer.cgmlp.ConvolutionalSpatialGatingUnit"]], "espnet_initialization_fn() (wenet.branchformer.cgmlp.convolutionalspatialgatingunit method)": [[14, "wenet.branchformer.cgmlp.ConvolutionalSpatialGatingUnit.espnet_initialization_fn"]], "forward() (wenet.branchformer.cgmlp.convolutionalgatingmlp method)": [[14, "wenet.branchformer.cgmlp.ConvolutionalGatingMLP.forward"]], "forward() (wenet.branchformer.cgmlp.convolutionalspatialgatingunit method)": [[14, "wenet.branchformer.cgmlp.ConvolutionalSpatialGatingUnit.forward"]], "training (wenet.branchformer.cgmlp.convolutionalgatingmlp attribute)": [[14, "wenet.branchformer.cgmlp.ConvolutionalGatingMLP.training"]], "training (wenet.branchformer.cgmlp.convolutionalspatialgatingunit attribute)": [[14, "wenet.branchformer.cgmlp.ConvolutionalSpatialGatingUnit.training"]], "wenet.branchformer.cgmlp": [[14, "module-wenet.branchformer.cgmlp"]], "nopositionalencoding (class in wenet.branchformer.embedding)": [[15, "wenet.branchformer.embedding.NoPositionalEncoding"]], "positionalencoding (class in wenet.branchformer.embedding)": [[15, "wenet.branchformer.embedding.PositionalEncoding"]], "relpositionalencoding (class in wenet.branchformer.embedding)": [[15, "wenet.branchformer.embedding.RelPositionalEncoding"]], "scaledpositionalencoding (class in wenet.branchformer.embedding)": [[15, "wenet.branchformer.embedding.ScaledPositionalEncoding"]], "forward() (wenet.branchformer.embedding.nopositionalencoding method)": [[15, "wenet.branchformer.embedding.NoPositionalEncoding.forward"]], "forward() (wenet.branchformer.embedding.positionalencoding method)": [[15, "wenet.branchformer.embedding.PositionalEncoding.forward"]], "forward() (wenet.branchformer.embedding.relpositionalencoding method)": [[15, "wenet.branchformer.embedding.RelPositionalEncoding.forward"]], "forward() (wenet.branchformer.embedding.scaledpositionalencoding method)": [[15, "wenet.branchformer.embedding.ScaledPositionalEncoding.forward"]], "position_encoding() (wenet.branchformer.embedding.nopositionalencoding method)": [[15, "wenet.branchformer.embedding.NoPositionalEncoding.position_encoding"]], "position_encoding() (wenet.branchformer.embedding.positionalencoding method)": [[15, "wenet.branchformer.embedding.PositionalEncoding.position_encoding"]], "reset_parameters() (wenet.branchformer.embedding.scaledpositionalencoding method)": [[15, "wenet.branchformer.embedding.ScaledPositionalEncoding.reset_parameters"]], "training (wenet.branchformer.embedding.nopositionalencoding attribute)": [[15, "wenet.branchformer.embedding.NoPositionalEncoding.training"]], "training (wenet.branchformer.embedding.positionalencoding attribute)": [[15, "wenet.branchformer.embedding.PositionalEncoding.training"]], "training (wenet.branchformer.embedding.relpositionalencoding attribute)": [[15, "wenet.branchformer.embedding.RelPositionalEncoding.training"]], "training (wenet.branchformer.embedding.scaledpositionalencoding attribute)": [[15, "wenet.branchformer.embedding.ScaledPositionalEncoding.training"]], "wenet.branchformer.embedding": [[15, "module-wenet.branchformer.embedding"]], "branchformerencoder (class in wenet.branchformer.encoder)": [[16, "wenet.branchformer.encoder.BranchformerEncoder"]], "forward() (wenet.branchformer.encoder.branchformerencoder method)": [[16, "wenet.branchformer.encoder.BranchformerEncoder.forward"]], "forward_chunk() (wenet.branchformer.encoder.branchformerencoder method)": [[16, "wenet.branchformer.encoder.BranchformerEncoder.forward_chunk"]], "forward_chunk_by_chunk() (wenet.branchformer.encoder.branchformerencoder method)": [[16, "wenet.branchformer.encoder.BranchformerEncoder.forward_chunk_by_chunk"]], "output_size() (wenet.branchformer.encoder.branchformerencoder method)": [[16, "wenet.branchformer.encoder.BranchformerEncoder.output_size"]], "training (wenet.branchformer.encoder.branchformerencoder attribute)": [[16, "wenet.branchformer.encoder.BranchformerEncoder.training"]], "wenet.branchformer.encoder": [[16, "module-wenet.branchformer.encoder"]], "branchformerencoderlayer (class in wenet.branchformer.encoder_layer)": [[17, "wenet.branchformer.encoder_layer.BranchformerEncoderLayer"]], "forward() (wenet.branchformer.encoder_layer.branchformerencoderlayer method)": [[17, "wenet.branchformer.encoder_layer.BranchformerEncoderLayer.forward"]], "training (wenet.branchformer.encoder_layer.branchformerencoderlayer attribute)": [[17, "wenet.branchformer.encoder_layer.BranchformerEncoderLayer.training"]], "wenet.branchformer.encoder_layer": [[17, "module-wenet.branchformer.encoder_layer"]], "wenet.dataset": [[19, "module-wenet.dataset"]], "datalist (class in wenet.dataset.dataset)": [[20, "wenet.dataset.dataset.DataList"]], "dataset() (in module wenet.dataset.dataset)": [[20, "wenet.dataset.dataset.Dataset"]], "distributedsampler (class in wenet.dataset.dataset)": [[20, "wenet.dataset.dataset.DistributedSampler"]], "processor (class in wenet.dataset.dataset)": [[20, "wenet.dataset.dataset.Processor"]], "apply() (wenet.dataset.dataset.processor method)": [[20, "wenet.dataset.dataset.Processor.apply"]], "sample() (wenet.dataset.dataset.distributedsampler method)": [[20, "wenet.dataset.dataset.DistributedSampler.sample"]], "set_epoch() (wenet.dataset.dataset.datalist method)": [[20, "wenet.dataset.dataset.DataList.set_epoch"]], "set_epoch() (wenet.dataset.dataset.distributedsampler method)": [[20, "wenet.dataset.dataset.DistributedSampler.set_epoch"]], "set_epoch() (wenet.dataset.dataset.processor method)": [[20, "wenet.dataset.dataset.Processor.set_epoch"]], "update() (wenet.dataset.dataset.distributedsampler method)": [[20, "wenet.dataset.dataset.DistributedSampler.update"]], "wenet.dataset.dataset": [[20, "module-wenet.dataset.dataset"]], "batch() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.batch"]], "compute_fbank() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.compute_fbank"]], "compute_mfcc() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.compute_mfcc"]], "dynamic_batch() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.dynamic_batch"]], "filter() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.filter"]], "padding() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.padding"]], "parse_raw() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.parse_raw"]], "resample() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.resample"]], "shuffle() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.shuffle"]], "sort() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.sort"]], "spec_aug() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.spec_aug"]], "spec_sub() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.spec_sub"]], "spec_trim() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.spec_trim"]], "speed_perturb() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.speed_perturb"]], "static_batch() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.static_batch"]], "tar_file_and_group() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.tar_file_and_group"]], "tokenize() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.tokenize"]], "url_opener() (in module wenet.dataset.processor)": [[22, "wenet.dataset.processor.url_opener"]], "wenet.dataset.processor": [[22, "module-wenet.dataset.processor"]], "amp2db() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.amp2db"]], "db2amp() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.db2amp"]], "distort() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.distort"]], "distort_chain() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.distort_chain"]], "distort_wav_conf() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.distort_wav_conf"]], "distort_wav_conf_and_save() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.distort_wav_conf_and_save"]], "generate_amp_mask() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.generate_amp_mask"]], "make_amp_mask() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.make_amp_mask"]], "make_fence_distortion() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.make_fence_distortion"]], "make_gain_db() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.make_gain_db"]], "make_jag_distortion() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.make_jag_distortion"]], "make_max_distortion() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.make_max_distortion"]], "make_poly_distortion() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.make_poly_distortion"]], "make_quad_distortion() (in module wenet.dataset.wav_distortion)": [[23, "wenet.dataset.wav_distortion.make_quad_distortion"]], "wenet.dataset.wav_distortion": [[23, "module-wenet.dataset.wav_distortion"]], "wenet.efficient_conformer": [[24, "module-wenet.efficient_conformer"]], "groupedrelpositionmultiheadedattention (class in wenet.efficient_conformer.attention)": [[25, "wenet.efficient_conformer.attention.GroupedRelPositionMultiHeadedAttention"]], "forward() (wenet.efficient_conformer.attention.groupedrelpositionmultiheadedattention method)": [[25, "wenet.efficient_conformer.attention.GroupedRelPositionMultiHeadedAttention.forward"]], "forward_attention() (wenet.efficient_conformer.attention.groupedrelpositionmultiheadedattention method)": [[25, "wenet.efficient_conformer.attention.GroupedRelPositionMultiHeadedAttention.forward_attention"]], "pad4group() (wenet.efficient_conformer.attention.groupedrelpositionmultiheadedattention method)": [[25, "wenet.efficient_conformer.attention.GroupedRelPositionMultiHeadedAttention.pad4group"]], "rel_shift() (wenet.efficient_conformer.attention.groupedrelpositionmultiheadedattention method)": [[25, "wenet.efficient_conformer.attention.GroupedRelPositionMultiHeadedAttention.rel_shift"]], "training (wenet.efficient_conformer.attention.groupedrelpositionmultiheadedattention attribute)": [[25, "wenet.efficient_conformer.attention.GroupedRelPositionMultiHeadedAttention.training"]], "wenet.efficient_conformer.attention": [[25, "module-wenet.efficient_conformer.attention"]], "convolutionmodule (class in wenet.efficient_conformer.convolution)": [[26, "wenet.efficient_conformer.convolution.ConvolutionModule"]], "forward() (wenet.efficient_conformer.convolution.convolutionmodule method)": [[26, "wenet.efficient_conformer.convolution.ConvolutionModule.forward"]], "training (wenet.efficient_conformer.convolution.convolutionmodule attribute)": [[26, "wenet.efficient_conformer.convolution.ConvolutionModule.training"]], "wenet.efficient_conformer.convolution": [[26, "module-wenet.efficient_conformer.convolution"]], "efficientconformerencoder (class in wenet.efficient_conformer.encoder)": [[27, "wenet.efficient_conformer.encoder.EfficientConformerEncoder"]], "calculate_downsampling_factor() (wenet.efficient_conformer.encoder.efficientconformerencoder method)": [[27, "wenet.efficient_conformer.encoder.EfficientConformerEncoder.calculate_downsampling_factor"]], "forward() (wenet.efficient_conformer.encoder.efficientconformerencoder method)": [[27, "wenet.efficient_conformer.encoder.EfficientConformerEncoder.forward"]], "forward_chunk() (wenet.efficient_conformer.encoder.efficientconformerencoder method)": [[27, "wenet.efficient_conformer.encoder.EfficientConformerEncoder.forward_chunk"]], "forward_chunk_by_chunk() (wenet.efficient_conformer.encoder.efficientconformerencoder method)": [[27, "wenet.efficient_conformer.encoder.EfficientConformerEncoder.forward_chunk_by_chunk"]], "output_size() (wenet.efficient_conformer.encoder.efficientconformerencoder method)": [[27, "wenet.efficient_conformer.encoder.EfficientConformerEncoder.output_size"]], "set_global_chunk_size() (wenet.efficient_conformer.encoder.efficientconformerencoder method)": [[27, "wenet.efficient_conformer.encoder.EfficientConformerEncoder.set_global_chunk_size"]], "training (wenet.efficient_conformer.encoder.efficientconformerencoder attribute)": [[27, "wenet.efficient_conformer.encoder.EfficientConformerEncoder.training"]], "wenet.efficient_conformer.encoder": [[27, "module-wenet.efficient_conformer.encoder"]], "strideconformerencoderlayer (class in wenet.efficient_conformer.encoder_layer)": [[28, "wenet.efficient_conformer.encoder_layer.StrideConformerEncoderLayer"]], "forward() (wenet.efficient_conformer.encoder_layer.strideconformerencoderlayer method)": [[28, "wenet.efficient_conformer.encoder_layer.StrideConformerEncoderLayer.forward"]], "training (wenet.efficient_conformer.encoder_layer.strideconformerencoderlayer attribute)": [[28, "wenet.efficient_conformer.encoder_layer.StrideConformerEncoderLayer.training"]], "wenet.efficient_conformer.encoder_layer": [[28, "module-wenet.efficient_conformer.encoder_layer"]], "conv2dsubsampling2 (class in wenet.efficient_conformer.subsampling)": [[29, "wenet.efficient_conformer.subsampling.Conv2dSubsampling2"]], "forward() (wenet.efficient_conformer.subsampling.conv2dsubsampling2 method)": [[29, "wenet.efficient_conformer.subsampling.Conv2dSubsampling2.forward"]], "training (wenet.efficient_conformer.subsampling.conv2dsubsampling2 attribute)": [[29, "wenet.efficient_conformer.subsampling.Conv2dSubsampling2.training"]], "wenet.efficient_conformer.subsampling": [[29, "module-wenet.efficient_conformer.subsampling"]], "wenet.squeezeformer": [[30, "module-wenet.squeezeformer"]], "relpositionmultiheadedattention (class in wenet.squeezeformer.attention)": [[31, "wenet.squeezeformer.attention.RelPositionMultiHeadedAttention"]], "forward() (wenet.squeezeformer.attention.relpositionmultiheadedattention method)": [[31, "wenet.squeezeformer.attention.RelPositionMultiHeadedAttention.forward"]], "forward_attention() (wenet.squeezeformer.attention.relpositionmultiheadedattention method)": [[31, "wenet.squeezeformer.attention.RelPositionMultiHeadedAttention.forward_attention"]], "init_weights() (wenet.squeezeformer.attention.relpositionmultiheadedattention method)": [[31, "wenet.squeezeformer.attention.RelPositionMultiHeadedAttention.init_weights"]], "rel_shift() (wenet.squeezeformer.attention.relpositionmultiheadedattention method)": [[31, "wenet.squeezeformer.attention.RelPositionMultiHeadedAttention.rel_shift"]], "training (wenet.squeezeformer.attention.relpositionmultiheadedattention attribute)": [[31, "wenet.squeezeformer.attention.RelPositionMultiHeadedAttention.training"]], "wenet.squeezeformer.attention": [[31, "module-wenet.squeezeformer.attention"]], "conv2dvalid (class in wenet.squeezeformer.conv2d)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid"]], "bias (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.bias"]], "dilation (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.dilation"]], "forward() (wenet.squeezeformer.conv2d.conv2dvalid method)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.forward"]], "groups (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.groups"]], "in_channels (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.in_channels"]], "kernel_size (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.kernel_size"]], "out_channels (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.out_channels"]], "output_padding (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.output_padding"]], "padding (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.padding"]], "padding_mode (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.padding_mode"]], "stride (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.stride"]], "transposed (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.transposed"]], "weight (wenet.squeezeformer.conv2d.conv2dvalid attribute)": [[32, "wenet.squeezeformer.conv2d.Conv2dValid.weight"]], "wenet.squeezeformer.conv2d": [[32, "module-wenet.squeezeformer.conv2d"]], "convolutionmodule (class in wenet.squeezeformer.convolution)": [[33, "wenet.squeezeformer.convolution.ConvolutionModule"]], "forward() (wenet.squeezeformer.convolution.convolutionmodule method)": [[33, "wenet.squeezeformer.convolution.ConvolutionModule.forward"]], "init_weights() (wenet.squeezeformer.convolution.convolutionmodule method)": [[33, "wenet.squeezeformer.convolution.ConvolutionModule.init_weights"]], "training (wenet.squeezeformer.convolution.convolutionmodule attribute)": [[33, "wenet.squeezeformer.convolution.ConvolutionModule.training"]], "wenet.squeezeformer.convolution": [[33, "module-wenet.squeezeformer.convolution"]], "squeezeformerencoder (class in wenet.squeezeformer.encoder)": [[34, "wenet.squeezeformer.encoder.SqueezeformerEncoder"]], "calculate_downsampling_factor() (wenet.squeezeformer.encoder.squeezeformerencoder method)": [[34, "wenet.squeezeformer.encoder.SqueezeformerEncoder.calculate_downsampling_factor"]], "check_ascending_list() (wenet.squeezeformer.encoder.squeezeformerencoder method)": [[34, "wenet.squeezeformer.encoder.SqueezeformerEncoder.check_ascending_list"]], "forward() (wenet.squeezeformer.encoder.squeezeformerencoder method)": [[34, "wenet.squeezeformer.encoder.SqueezeformerEncoder.forward"]], "forward_chunk() (wenet.squeezeformer.encoder.squeezeformerencoder method)": [[34, "wenet.squeezeformer.encoder.SqueezeformerEncoder.forward_chunk"]], "forward_chunk_by_chunk() (wenet.squeezeformer.encoder.squeezeformerencoder method)": [[34, "wenet.squeezeformer.encoder.SqueezeformerEncoder.forward_chunk_by_chunk"]], "output_size() (wenet.squeezeformer.encoder.squeezeformerencoder method)": [[34, "wenet.squeezeformer.encoder.SqueezeformerEncoder.output_size"]], "training (wenet.squeezeformer.encoder.squeezeformerencoder attribute)": [[34, "wenet.squeezeformer.encoder.SqueezeformerEncoder.training"]], "wenet.squeezeformer.encoder": [[34, "module-wenet.squeezeformer.encoder"]], "squeezeformerencoderlayer (class in wenet.squeezeformer.encoder_layer)": [[35, "wenet.squeezeformer.encoder_layer.SqueezeformerEncoderLayer"]], "forward() (wenet.squeezeformer.encoder_layer.squeezeformerencoderlayer method)": [[35, "wenet.squeezeformer.encoder_layer.SqueezeformerEncoderLayer.forward"]], "training (wenet.squeezeformer.encoder_layer.squeezeformerencoderlayer attribute)": [[35, "wenet.squeezeformer.encoder_layer.SqueezeformerEncoderLayer.training"]], "wenet.squeezeformer.encoder_layer": [[35, "module-wenet.squeezeformer.encoder_layer"]], "positionwisefeedforward (class in wenet.squeezeformer.positionwise_feed_forward)": [[36, "wenet.squeezeformer.positionwise_feed_forward.PositionwiseFeedForward"]], "forward() (wenet.squeezeformer.positionwise_feed_forward.positionwisefeedforward method)": [[36, "wenet.squeezeformer.positionwise_feed_forward.PositionwiseFeedForward.forward"]], "init_weights() (wenet.squeezeformer.positionwise_feed_forward.positionwisefeedforward method)": [[36, "wenet.squeezeformer.positionwise_feed_forward.PositionwiseFeedForward.init_weights"]], "training (wenet.squeezeformer.positionwise_feed_forward.positionwisefeedforward attribute)": [[36, "wenet.squeezeformer.positionwise_feed_forward.PositionwiseFeedForward.training"]], "wenet.squeezeformer.positionwise_feed_forward": [[36, "module-wenet.squeezeformer.positionwise_feed_forward"]], "depthwiseconv2dsubsampling4 (class in wenet.squeezeformer.subsampling)": [[37, "wenet.squeezeformer.subsampling.DepthwiseConv2dSubsampling4"]], "timereductionlayer1d (class in wenet.squeezeformer.subsampling)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayer1D"]], "timereductionlayer2d (class in wenet.squeezeformer.subsampling)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayer2D"]], "timereductionlayerstream (class in wenet.squeezeformer.subsampling)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayerStream"]], "forward() (wenet.squeezeformer.subsampling.depthwiseconv2dsubsampling4 method)": [[37, "wenet.squeezeformer.subsampling.DepthwiseConv2dSubsampling4.forward"]], "forward() (wenet.squeezeformer.subsampling.timereductionlayer1d method)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayer1D.forward"]], "forward() (wenet.squeezeformer.subsampling.timereductionlayer2d method)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayer2D.forward"]], "forward() (wenet.squeezeformer.subsampling.timereductionlayerstream method)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayerStream.forward"]], "init_weights() (wenet.squeezeformer.subsampling.timereductionlayer1d method)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayer1D.init_weights"]], "init_weights() (wenet.squeezeformer.subsampling.timereductionlayer2d method)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayer2D.init_weights"]], "init_weights() (wenet.squeezeformer.subsampling.timereductionlayerstream method)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayerStream.init_weights"]], "training (wenet.squeezeformer.subsampling.depthwiseconv2dsubsampling4 attribute)": [[37, "wenet.squeezeformer.subsampling.DepthwiseConv2dSubsampling4.training"]], "training (wenet.squeezeformer.subsampling.timereductionlayer1d attribute)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayer1D.training"]], "training (wenet.squeezeformer.subsampling.timereductionlayer2d attribute)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayer2D.training"]], "training (wenet.squeezeformer.subsampling.timereductionlayerstream attribute)": [[37, "wenet.squeezeformer.subsampling.TimeReductionLayerStream.training"]], "wenet.squeezeformer.subsampling": [[37, "module-wenet.squeezeformer.subsampling"]], "wenet.transducer": [[38, "module-wenet.transducer"]], "transducerjoint (class in wenet.transducer.joint)": [[39, "wenet.transducer.joint.TransducerJoint"]], "forward() (wenet.transducer.joint.transducerjoint method)": [[39, "wenet.transducer.joint.TransducerJoint.forward"]], "training (wenet.transducer.joint.transducerjoint attribute)": [[39, "wenet.transducer.joint.TransducerJoint.training"]], "wenet.transducer.joint": [[39, "module-wenet.transducer.joint"]], "applypadding() (in module wenet.transducer.predictor)": [[40, "wenet.transducer.predictor.ApplyPadding"]], "convpredictor (class in wenet.transducer.predictor)": [[40, "wenet.transducer.predictor.ConvPredictor"]], "embeddingpredictor (class in wenet.transducer.predictor)": [[40, "wenet.transducer.predictor.EmbeddingPredictor"]], "predictorbase (class in wenet.transducer.predictor)": [[40, "wenet.transducer.predictor.PredictorBase"]], "rnnpredictor (class in wenet.transducer.predictor)": [[40, "wenet.transducer.predictor.RNNPredictor"]], "batch_to_cache() (wenet.transducer.predictor.convpredictor method)": [[40, "wenet.transducer.predictor.ConvPredictor.batch_to_cache"]], "batch_to_cache() (wenet.transducer.predictor.embeddingpredictor method)": [[40, "wenet.transducer.predictor.EmbeddingPredictor.batch_to_cache"]], "batch_to_cache() (wenet.transducer.predictor.predictorbase method)": [[40, "wenet.transducer.predictor.PredictorBase.batch_to_cache"]], "batch_to_cache() (wenet.transducer.predictor.rnnpredictor method)": [[40, "wenet.transducer.predictor.RNNPredictor.batch_to_cache"]], "cache_to_batch() (wenet.transducer.predictor.convpredictor method)": [[40, "wenet.transducer.predictor.ConvPredictor.cache_to_batch"]], "cache_to_batch() (wenet.transducer.predictor.embeddingpredictor method)": [[40, "wenet.transducer.predictor.EmbeddingPredictor.cache_to_batch"]], "cache_to_batch() (wenet.transducer.predictor.predictorbase method)": [[40, "wenet.transducer.predictor.PredictorBase.cache_to_batch"]], "cache_to_batch() (wenet.transducer.predictor.rnnpredictor method)": [[40, "wenet.transducer.predictor.RNNPredictor.cache_to_batch"]], "forward() (wenet.transducer.predictor.convpredictor method)": [[40, "wenet.transducer.predictor.ConvPredictor.forward"]], "forward() (wenet.transducer.predictor.embeddingpredictor method)": [[40, "wenet.transducer.predictor.EmbeddingPredictor.forward"]], "forward() (wenet.transducer.predictor.predictorbase method)": [[40, "wenet.transducer.predictor.PredictorBase.forward"]], "forward() (wenet.transducer.predictor.rnnpredictor method)": [[40, "wenet.transducer.predictor.RNNPredictor.forward"]], "forward_step() (wenet.transducer.predictor.convpredictor method)": [[40, "wenet.transducer.predictor.ConvPredictor.forward_step"]], "forward_step() (wenet.transducer.predictor.embeddingpredictor method)": [[40, "wenet.transducer.predictor.EmbeddingPredictor.forward_step"]], "forward_step() (wenet.transducer.predictor.predictorbase method)": [[40, "wenet.transducer.predictor.PredictorBase.forward_step"]], "forward_step() (wenet.transducer.predictor.rnnpredictor method)": [[40, "wenet.transducer.predictor.RNNPredictor.forward_step"]], "init_state() (wenet.transducer.predictor.convpredictor method)": [[40, "wenet.transducer.predictor.ConvPredictor.init_state"]], "init_state() (wenet.transducer.predictor.embeddingpredictor method)": [[40, "wenet.transducer.predictor.EmbeddingPredictor.init_state"]], "init_state() (wenet.transducer.predictor.predictorbase method)": [[40, "wenet.transducer.predictor.PredictorBase.init_state"]], "init_state() (wenet.transducer.predictor.rnnpredictor method)": [[40, "wenet.transducer.predictor.RNNPredictor.init_state"]], "training (wenet.transducer.predictor.convpredictor attribute)": [[40, "wenet.transducer.predictor.ConvPredictor.training"]], "training (wenet.transducer.predictor.embeddingpredictor attribute)": [[40, "wenet.transducer.predictor.EmbeddingPredictor.training"]], "training (wenet.transducer.predictor.predictorbase attribute)": [[40, "wenet.transducer.predictor.PredictorBase.training"]], "training (wenet.transducer.predictor.rnnpredictor attribute)": [[40, "wenet.transducer.predictor.RNNPredictor.training"]], "wenet.transducer.predictor": [[40, "module-wenet.transducer.predictor"]], "transducer (class in wenet.transducer.transducer)": [[41, "wenet.transducer.transducer.Transducer"]], "beam_search() (wenet.transducer.transducer.transducer method)": [[41, "wenet.transducer.transducer.Transducer.beam_search"]], "forward() (wenet.transducer.transducer.transducer method)": [[41, "wenet.transducer.transducer.Transducer.forward"]], "forward_encoder_chunk() (wenet.transducer.transducer.transducer method)": [[41, "wenet.transducer.transducer.Transducer.forward_encoder_chunk"]], "forward_joint_step() (wenet.transducer.transducer.transducer method)": [[41, "wenet.transducer.transducer.Transducer.forward_joint_step"]], "forward_predictor_init_state() (wenet.transducer.transducer.transducer method)": [[41, "wenet.transducer.transducer.Transducer.forward_predictor_init_state"]], "forward_predictor_step() (wenet.transducer.transducer.transducer method)": [[41, "wenet.transducer.transducer.Transducer.forward_predictor_step"]], "greedy_search() (wenet.transducer.transducer.transducer method)": [[41, "wenet.transducer.transducer.Transducer.greedy_search"]], "init_bs() (wenet.transducer.transducer.transducer method)": [[41, "wenet.transducer.transducer.Transducer.init_bs"]], "training (wenet.transducer.transducer.transducer attribute)": [[41, "wenet.transducer.transducer.Transducer.training"]], "transducer_attention_rescoring() (wenet.transducer.transducer.transducer method)": [[41, "wenet.transducer.transducer.Transducer.transducer_attention_rescoring"]], "wenet.transducer.transducer": [[41, "module-wenet.transducer.transducer"]], "wenet.transformer": [[42, "module-wenet.transformer"]], "asrmodel (class in wenet.transformer.asr_model)": [[43, "wenet.transformer.asr_model.ASRModel"]], "attention_rescoring() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.attention_rescoring"]], "ctc_activation() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.ctc_activation"]], "ctc_greedy_search() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.ctc_greedy_search"]], "ctc_prefix_beam_search() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.ctc_prefix_beam_search"]], "eos_symbol() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.eos_symbol"]], "forward() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.forward"]], "forward_attention_decoder() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.forward_attention_decoder"]], "forward_encoder_chunk() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.forward_encoder_chunk"]], "hlg_onebest() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.hlg_onebest"]], "hlg_rescore() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.hlg_rescore"]], "is_bidirectional_decoder() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.is_bidirectional_decoder"]], "load_hlg_resource_if_necessary() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.load_hlg_resource_if_necessary"]], "load_lfmmi_resource() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.load_lfmmi_resource"]], "recognize() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.recognize"]], "right_context() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.right_context"]], "sos_symbol() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.sos_symbol"]], "subsampling_rate() (wenet.transformer.asr_model.asrmodel method)": [[43, "wenet.transformer.asr_model.ASRModel.subsampling_rate"]], "training (wenet.transformer.asr_model.asrmodel attribute)": [[43, "wenet.transformer.asr_model.ASRModel.training"]], "wenet.transformer.asr_model": [[43, "module-wenet.transformer.asr_model"]], "multiheadedattention (class in wenet.transformer.attention)": [[44, "wenet.transformer.attention.MultiHeadedAttention"]], "relpositionmultiheadedattention (class in wenet.transformer.attention)": [[44, "wenet.transformer.attention.RelPositionMultiHeadedAttention"]], "forward() (wenet.transformer.attention.multiheadedattention method)": [[44, "wenet.transformer.attention.MultiHeadedAttention.forward"]], "forward() (wenet.transformer.attention.relpositionmultiheadedattention method)": [[44, "wenet.transformer.attention.RelPositionMultiHeadedAttention.forward"]], "forward_attention() (wenet.transformer.attention.multiheadedattention method)": [[44, "wenet.transformer.attention.MultiHeadedAttention.forward_attention"]], "forward_qkv() (wenet.transformer.attention.multiheadedattention method)": [[44, "wenet.transformer.attention.MultiHeadedAttention.forward_qkv"]], "rel_shift() (wenet.transformer.attention.relpositionmultiheadedattention method)": [[44, "wenet.transformer.attention.RelPositionMultiHeadedAttention.rel_shift"]], "training (wenet.transformer.attention.multiheadedattention attribute)": [[44, "wenet.transformer.attention.MultiHeadedAttention.training"]], "training (wenet.transformer.attention.relpositionmultiheadedattention attribute)": [[44, "wenet.transformer.attention.RelPositionMultiHeadedAttention.training"]], "wenet.transformer.attention": [[44, "module-wenet.transformer.attention"]], "globalcmvn (class in wenet.transformer.cmvn)": [[45, "wenet.transformer.cmvn.GlobalCMVN"]], "forward() (wenet.transformer.cmvn.globalcmvn method)": [[45, "wenet.transformer.cmvn.GlobalCMVN.forward"]], "training (wenet.transformer.cmvn.globalcmvn attribute)": [[45, "wenet.transformer.cmvn.GlobalCMVN.training"]], "wenet.transformer.cmvn": [[45, "module-wenet.transformer.cmvn"]], "convolutionmodule (class in wenet.transformer.convolution)": [[46, "wenet.transformer.convolution.ConvolutionModule"]], "forward() (wenet.transformer.convolution.convolutionmodule method)": [[46, "wenet.transformer.convolution.ConvolutionModule.forward"]], "training (wenet.transformer.convolution.convolutionmodule attribute)": [[46, "wenet.transformer.convolution.ConvolutionModule.training"]], "wenet.transformer.convolution": [[46, "module-wenet.transformer.convolution"]], "ctc (class in wenet.transformer.ctc)": [[47, "wenet.transformer.ctc.CTC"]], "argmax() (wenet.transformer.ctc.ctc method)": [[47, "wenet.transformer.ctc.CTC.argmax"]], "forward() (wenet.transformer.ctc.ctc method)": [[47, "wenet.transformer.ctc.CTC.forward"]], "log_softmax() (wenet.transformer.ctc.ctc method)": [[47, "wenet.transformer.ctc.CTC.log_softmax"]], "training (wenet.transformer.ctc.ctc attribute)": [[47, "wenet.transformer.ctc.CTC.training"]], "wenet.transformer.ctc": [[47, "module-wenet.transformer.ctc"]], "bitransformerdecoder (class in wenet.transformer.decoder)": [[48, "wenet.transformer.decoder.BiTransformerDecoder"]], "transformerdecoder (class in wenet.transformer.decoder)": [[48, "wenet.transformer.decoder.TransformerDecoder"]], "forward() (wenet.transformer.decoder.bitransformerdecoder method)": [[48, "wenet.transformer.decoder.BiTransformerDecoder.forward"]], "forward() (wenet.transformer.decoder.transformerdecoder method)": [[48, "wenet.transformer.decoder.TransformerDecoder.forward"]], "forward_one_step() (wenet.transformer.decoder.bitransformerdecoder method)": [[48, "wenet.transformer.decoder.BiTransformerDecoder.forward_one_step"]], "forward_one_step() (wenet.transformer.decoder.transformerdecoder method)": [[48, "wenet.transformer.decoder.TransformerDecoder.forward_one_step"]], "training (wenet.transformer.decoder.bitransformerdecoder attribute)": [[48, "wenet.transformer.decoder.BiTransformerDecoder.training"]], "training (wenet.transformer.decoder.transformerdecoder attribute)": [[48, "wenet.transformer.decoder.TransformerDecoder.training"]], "wenet.transformer.decoder": [[48, "module-wenet.transformer.decoder"]], "decoderlayer (class in wenet.transformer.decoder_layer)": [[49, "wenet.transformer.decoder_layer.DecoderLayer"]], "forward() (wenet.transformer.decoder_layer.decoderlayer method)": [[49, "wenet.transformer.decoder_layer.DecoderLayer.forward"]], "training (wenet.transformer.decoder_layer.decoderlayer attribute)": [[49, "wenet.transformer.decoder_layer.DecoderLayer.training"]], "wenet.transformer.decoder_layer": [[49, "module-wenet.transformer.decoder_layer"]], "nopositionalencoding (class in wenet.transformer.embedding)": [[50, "wenet.transformer.embedding.NoPositionalEncoding"]], "positionalencoding (class in wenet.transformer.embedding)": [[50, "wenet.transformer.embedding.PositionalEncoding"]], "relpositionalencoding (class in wenet.transformer.embedding)": [[50, "wenet.transformer.embedding.RelPositionalEncoding"]], "forward() (wenet.transformer.embedding.nopositionalencoding method)": [[50, "wenet.transformer.embedding.NoPositionalEncoding.forward"]], "forward() (wenet.transformer.embedding.positionalencoding method)": [[50, "wenet.transformer.embedding.PositionalEncoding.forward"]], "forward() (wenet.transformer.embedding.relpositionalencoding method)": [[50, "wenet.transformer.embedding.RelPositionalEncoding.forward"]], "position_encoding() (wenet.transformer.embedding.nopositionalencoding method)": [[50, "wenet.transformer.embedding.NoPositionalEncoding.position_encoding"]], "position_encoding() (wenet.transformer.embedding.positionalencoding method)": [[50, "wenet.transformer.embedding.PositionalEncoding.position_encoding"]], "training (wenet.transformer.embedding.nopositionalencoding attribute)": [[50, "wenet.transformer.embedding.NoPositionalEncoding.training"]], "training (wenet.transformer.embedding.positionalencoding attribute)": [[50, "wenet.transformer.embedding.PositionalEncoding.training"]], "training (wenet.transformer.embedding.relpositionalencoding attribute)": [[50, "wenet.transformer.embedding.RelPositionalEncoding.training"]], "wenet.transformer.embedding": [[50, "module-wenet.transformer.embedding"]], "baseencoder (class in wenet.transformer.encoder)": [[51, "wenet.transformer.encoder.BaseEncoder"]], "conformerencoder (class in wenet.transformer.encoder)": [[51, "wenet.transformer.encoder.ConformerEncoder"]], "transformerencoder (class in wenet.transformer.encoder)": [[51, "wenet.transformer.encoder.TransformerEncoder"]], "forward() (wenet.transformer.encoder.baseencoder method)": [[51, "wenet.transformer.encoder.BaseEncoder.forward"]], "forward_chunk() (wenet.transformer.encoder.baseencoder method)": [[51, "wenet.transformer.encoder.BaseEncoder.forward_chunk"]], "forward_chunk_by_chunk() (wenet.transformer.encoder.baseencoder method)": [[51, "wenet.transformer.encoder.BaseEncoder.forward_chunk_by_chunk"]], "output_size() (wenet.transformer.encoder.baseencoder method)": [[51, "wenet.transformer.encoder.BaseEncoder.output_size"]], "training (wenet.transformer.encoder.baseencoder attribute)": [[51, "wenet.transformer.encoder.BaseEncoder.training"]], "training (wenet.transformer.encoder.conformerencoder attribute)": [[51, "wenet.transformer.encoder.ConformerEncoder.training"]], "training (wenet.transformer.encoder.transformerencoder attribute)": [[51, "wenet.transformer.encoder.TransformerEncoder.training"]], "wenet.transformer.encoder": [[51, "module-wenet.transformer.encoder"]], "conformerencoderlayer (class in wenet.transformer.encoder_layer)": [[52, "wenet.transformer.encoder_layer.ConformerEncoderLayer"]], "transformerencoderlayer (class in wenet.transformer.encoder_layer)": [[52, "wenet.transformer.encoder_layer.TransformerEncoderLayer"]], "forward() (wenet.transformer.encoder_layer.conformerencoderlayer method)": [[52, "wenet.transformer.encoder_layer.ConformerEncoderLayer.forward"]], "forward() (wenet.transformer.encoder_layer.transformerencoderlayer method)": [[52, "wenet.transformer.encoder_layer.TransformerEncoderLayer.forward"]], "training (wenet.transformer.encoder_layer.conformerencoderlayer attribute)": [[52, "wenet.transformer.encoder_layer.ConformerEncoderLayer.training"]], "training (wenet.transformer.encoder_layer.transformerencoderlayer attribute)": [[52, "wenet.transformer.encoder_layer.TransformerEncoderLayer.training"]], "wenet.transformer.encoder_layer": [[52, "module-wenet.transformer.encoder_layer"]], "labelsmoothingloss (class in wenet.transformer.label_smoothing_loss)": [[53, "wenet.transformer.label_smoothing_loss.LabelSmoothingLoss"]], "forward() (wenet.transformer.label_smoothing_loss.labelsmoothingloss method)": [[53, "wenet.transformer.label_smoothing_loss.LabelSmoothingLoss.forward"]], "training (wenet.transformer.label_smoothing_loss.labelsmoothingloss attribute)": [[53, "wenet.transformer.label_smoothing_loss.LabelSmoothingLoss.training"]], "wenet.transformer.label_smoothing_loss": [[53, "module-wenet.transformer.label_smoothing_loss"]], "positionwisefeedforward (class in wenet.transformer.positionwise_feed_forward)": [[54, "wenet.transformer.positionwise_feed_forward.PositionwiseFeedForward"]], "forward() (wenet.transformer.positionwise_feed_forward.positionwisefeedforward method)": [[54, "wenet.transformer.positionwise_feed_forward.PositionwiseFeedForward.forward"]], "training (wenet.transformer.positionwise_feed_forward.positionwisefeedforward attribute)": [[54, "wenet.transformer.positionwise_feed_forward.PositionwiseFeedForward.training"]], "wenet.transformer.positionwise_feed_forward": [[54, "module-wenet.transformer.positionwise_feed_forward"]], "basesubsampling (class in wenet.transformer.subsampling)": [[55, "wenet.transformer.subsampling.BaseSubsampling"]], "conv2dsubsampling4 (class in wenet.transformer.subsampling)": [[55, "wenet.transformer.subsampling.Conv2dSubsampling4"]], "conv2dsubsampling6 (class in wenet.transformer.subsampling)": [[55, "wenet.transformer.subsampling.Conv2dSubsampling6"]], "conv2dsubsampling8 (class in wenet.transformer.subsampling)": [[55, "wenet.transformer.subsampling.Conv2dSubsampling8"]], "linearnosubsampling (class in wenet.transformer.subsampling)": [[55, "wenet.transformer.subsampling.LinearNoSubsampling"]], "forward() (wenet.transformer.subsampling.conv2dsubsampling4 method)": [[55, "wenet.transformer.subsampling.Conv2dSubsampling4.forward"]], "forward() (wenet.transformer.subsampling.conv2dsubsampling6 method)": [[55, "wenet.transformer.subsampling.Conv2dSubsampling6.forward"]], "forward() (wenet.transformer.subsampling.conv2dsubsampling8 method)": [[55, "wenet.transformer.subsampling.Conv2dSubsampling8.forward"]], "forward() (wenet.transformer.subsampling.linearnosubsampling method)": [[55, "wenet.transformer.subsampling.LinearNoSubsampling.forward"]], "position_encoding() (wenet.transformer.subsampling.basesubsampling method)": [[55, "wenet.transformer.subsampling.BaseSubsampling.position_encoding"]], "training (wenet.transformer.subsampling.basesubsampling attribute)": [[55, "wenet.transformer.subsampling.BaseSubsampling.training"]], "training (wenet.transformer.subsampling.conv2dsubsampling4 attribute)": [[55, "wenet.transformer.subsampling.Conv2dSubsampling4.training"]], "training (wenet.transformer.subsampling.conv2dsubsampling6 attribute)": [[55, "wenet.transformer.subsampling.Conv2dSubsampling6.training"]], "training (wenet.transformer.subsampling.conv2dsubsampling8 attribute)": [[55, "wenet.transformer.subsampling.Conv2dSubsampling8.training"]], "training (wenet.transformer.subsampling.linearnosubsampling attribute)": [[55, "wenet.transformer.subsampling.LinearNoSubsampling.training"]], "wenet.transformer.subsampling": [[55, "module-wenet.transformer.subsampling"]], "swish (class in wenet.transformer.swish)": [[56, "wenet.transformer.swish.Swish"]], "forward() (wenet.transformer.swish.swish method)": [[56, "wenet.transformer.swish.Swish.forward"]], "training (wenet.transformer.swish.swish attribute)": [[56, "wenet.transformer.swish.Swish.training"]], "wenet.transformer.swish": [[56, "module-wenet.transformer.swish"]], "wenet.utils": [[57, "module-wenet.utils"]], "add_blank() (in module wenet.utils.common)": [[60, "wenet.utils.common.add_blank"]], "add_sos_eos() (in module wenet.utils.common)": [[60, "wenet.utils.common.add_sos_eos"]], "get_activation() (in module wenet.utils.common)": [[60, "wenet.utils.common.get_activation"]], "get_rnn() (in module wenet.utils.common)": [[60, "wenet.utils.common.get_rnn"]], "get_subsample() (in module wenet.utils.common)": [[60, "wenet.utils.common.get_subsample"]], "log_add() (in module wenet.utils.common)": [[60, "wenet.utils.common.log_add"]], "pad_list() (in module wenet.utils.common)": [[60, "wenet.utils.common.pad_list"]], "remove_duplicates_and_blank() (in module wenet.utils.common)": [[60, "wenet.utils.common.remove_duplicates_and_blank"]], "replace_duplicates_with_blank() (in module wenet.utils.common)": [[60, "wenet.utils.common.replace_duplicates_with_blank"]], "reverse_pad_list() (in module wenet.utils.common)": [[60, "wenet.utils.common.reverse_pad_list"]], "th_accuracy() (in module wenet.utils.common)": [[60, "wenet.utils.common.th_accuracy"]], "wenet.utils.common": [[60, "module-wenet.utils.common"]], "override_config() (in module wenet.utils.config)": [[61, "wenet.utils.config.override_config"]], "wenet.utils.config": [[61, "module-wenet.utils.config"]], "executor (class in wenet.utils.executor)": [[63, "wenet.utils.executor.Executor"]], "cv() (wenet.utils.executor.executor method)": [[63, "wenet.utils.executor.Executor.cv"]], "train() (wenet.utils.executor.executor method)": [[63, "wenet.utils.executor.Executor.train"]], "wenet.utils.executor": [[63, "module-wenet.utils.executor"]], "read_lists() (in module wenet.utils.file_utils)": [[64, "wenet.utils.file_utils.read_lists"]], "read_non_lang_symbols() (in module wenet.utils.file_utils)": [[64, "wenet.utils.file_utils.read_non_lang_symbols"]], "read_symbol_table() (in module wenet.utils.file_utils)": [[64, "wenet.utils.file_utils.read_symbol_table"]], "wenet.utils.file_utils": [[64, "module-wenet.utils.file_utils"]], "add_optional_chunk_mask() (in module wenet.utils.mask)": [[66, "wenet.utils.mask.add_optional_chunk_mask"]], "make_non_pad_mask() (in module wenet.utils.mask)": [[66, "wenet.utils.mask.make_non_pad_mask"]], "make_pad_mask() (in module wenet.utils.mask)": [[66, "wenet.utils.mask.make_pad_mask"]], "mask_finished_preds() (in module wenet.utils.mask)": [[66, "wenet.utils.mask.mask_finished_preds"]], "mask_finished_scores() (in module wenet.utils.mask)": [[66, "wenet.utils.mask.mask_finished_scores"]], "subsequent_chunk_mask() (in module wenet.utils.mask)": [[66, "wenet.utils.mask.subsequent_chunk_mask"]], "subsequent_mask() (in module wenet.utils.mask)": [[66, "wenet.utils.mask.subsequent_mask"]], "wenet.utils.mask": [[66, "module-wenet.utils.mask"]], "cosineannealing (class in wenet.utils.scheduler)": [[67, "wenet.utils.scheduler.CosineAnnealing"]], "noamannealing (class in wenet.utils.scheduler)": [[67, "wenet.utils.scheduler.NoamAnnealing"]], "noamholdannealing (class in wenet.utils.scheduler)": [[67, "wenet.utils.scheduler.NoamHoldAnnealing"]], "squareannealing (class in wenet.utils.scheduler)": [[67, "wenet.utils.scheduler.SquareAnnealing"]], "squarerootannealing (class in wenet.utils.scheduler)": [[67, "wenet.utils.scheduler.SquareRootAnnealing"]], "squarerootconstantpolicy (class in wenet.utils.scheduler)": [[67, "wenet.utils.scheduler.SquareRootConstantPolicy"]], "warmupannealholdpolicy (class in wenet.utils.scheduler)": [[67, "wenet.utils.scheduler.WarmupAnnealHoldPolicy"]], "warmupholdpolicy (class in wenet.utils.scheduler)": [[67, "wenet.utils.scheduler.WarmupHoldPolicy"]], "warmuplr (class in wenet.utils.scheduler)": [[67, "wenet.utils.scheduler.WarmupLR"]], "warmuppolicy (class in wenet.utils.scheduler)": [[67, "wenet.utils.scheduler.WarmupPolicy"]], "get_lr() (wenet.utils.scheduler.noamannealing method)": [[67, "wenet.utils.scheduler.NoamAnnealing.get_lr"]], "get_lr() (wenet.utils.scheduler.squarerootconstantpolicy method)": [[67, "wenet.utils.scheduler.SquareRootConstantPolicy.get_lr"]], "get_lr() (wenet.utils.scheduler.warmupannealholdpolicy method)": [[67, "wenet.utils.scheduler.WarmupAnnealHoldPolicy.get_lr"]], "get_lr() (wenet.utils.scheduler.warmupholdpolicy method)": [[67, "wenet.utils.scheduler.WarmupHoldPolicy.get_lr"]], "get_lr() (wenet.utils.scheduler.warmuplr method)": [[67, "wenet.utils.scheduler.WarmupLR.get_lr"]], "get_lr() (wenet.utils.scheduler.warmuppolicy method)": [[67, "wenet.utils.scheduler.WarmupPolicy.get_lr"]], "set_step() (wenet.utils.scheduler.noamholdannealing method)": [[67, "wenet.utils.scheduler.NoamHoldAnnealing.set_step"]], "set_step() (wenet.utils.scheduler.warmuplr method)": [[67, "wenet.utils.scheduler.WarmupLR.set_step"]], "wenet.utils.scheduler": [[67, "module-wenet.utils.scheduler"]]}})